<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>商品中台系统的一些设计思考</title>
      <link href="/2020/05/13/shang-pin-zhong-tai-xi-tong-de-yi-xie-she-ji-si-kao/"/>
      <url>/2020/05/13/shang-pin-zhong-tai-xi-tong-de-yi-xie-she-ji-si-kao/</url>
      
        <content type="html"><![CDATA[<p>今天分享实现中台系统中的一些设计思考</p><h3 id="系统目标"><a href="#系统目标" class="headerlink" title="系统目标"></a>系统目标</h3><ul><li>搭建商品中心系统和服务，支持多个业务线产品的统一存储和输出</li><li>数据进去中台系统到可用，延迟不超过5分钟</li><li>满足接收消息qps超过2000</li></ul><h3 id="系统设计"><a href="#系统设计" class="headerlink" title="系统设计"></a>系统设计</h3><ul><li>系统分三个模块，分别负责数据落地，数据搜索和数据详情</li><li>使用 ES 作为搜索引擎，使用 Redis 作为数据缓存系统<br><img src="/images/zt_jg.png" alt="系统架构简图"></li></ul><h3 id="遇到的一些问题"><a href="#遇到的一些问题" class="headerlink" title="遇到的一些问题"></a>遇到的一些问题</h3><ul><li>多个业务系统在中台流程不能相互影响</li><li>考虑依赖方的接口性能和承受能力</li><li>控制处理延时</li><li>分表生成中台唯一主键</li><li>变更事件过来时不一定能获取到所需的数据</li></ul><h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><ul><li>给不同业务线分配不同的消息topic，避免相互影响</li><li>接收处进行限流设置，对应全量等流量尖峰有控制</li><li>依赖接口保证各自的相应，控制自己的请求频率和批量数量</li><li>自实现id生成器（分布式锁+id表）</li><li>接收消息后延迟执行，便于收集到完整数据</li></ul><h3 id="一些心得"><a href="#一些心得" class="headerlink" title="一些心得"></a>一些心得</h3><ul><li>系统设计中需要进行限速，防止突发高峰影响系统整体运转</li><li>系统中对于应用重启、崩溃等都进行考虑，防止数据丢失</li><li>各个地方建立全量机制保持数据一致</li><li>建立数据补偿机制，如下游查不到出发数据获取流程</li></ul>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>项目中接口性能优化</title>
      <link href="/2020/04/13/xiang-mu-zhong-jie-kou-xing-neng-you-hua/"/>
      <url>/2020/04/13/xiang-mu-zhong-jie-kou-xing-neng-you-hua/</url>
      
        <content type="html"><![CDATA[<p>今天分享下项目中使用缓存对项目进行性能优化</p><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><ul><li>项目中流量高峰时，db的qps达到15k左右，线程数达到5k（服务器设置的最大连接数），创建链接最高耗费达到2s。数据库服务器的连接数以及cpu升高，处理能力下降，响应时间变长</li><li>接口提供的批量接口查询很多资源，设计到大量班期时存在性能问题</li></ul><h3 id="原因分析"><a href="#原因分析" class="headerlink" title="原因分析"></a>原因分析</h3><ul><li>库存服务没有针对请求区分核心流程和非核心流程，所有读写操作都是直接操作写库</li><li>当非核心（可降级）的查询量大时，直接影响了核心应用的可用性，间接影响到了订单环节的扣还库存等相关操作</li><li>接口内缓存使用不充分</li></ul><h3 id="优化方案"><a href="#优化方案" class="headerlink" title="优化方案"></a>优化方案</h3><ul><li>核心与非核心隔离<ul><li>核心应用： 特点：数据实时性要求高，请求量小，对服务稳定性要求高，影响预订和订单；单独部署</li><li>非核心应用：特点：数据实时性要求相对较低，请求量大，对服务稳定性相对较低，不影响预订和下单，可降级处理</li><li>对于非核心应用的调用，当服务的可用性降低，比如redis故障请求击穿缓存都命中db，对db造成压力的情    况下，避免影响核心应用，使用开关控制，切换成无限库存模式</li></ul></li><li>针对非核心的查询使用从库<ul><li>主从分离</li></ul></li><li>接口使用多级缓存优化查询性能<ul><li>数据更新需要主动更新缓存以保证缓存的数据实时性</li><li>对于未更新的数据，使用被动更新缓存，提高缓存命中率</li><li>适当提高缓存时间</li><li>对于查无结果的数据，使用特殊对象填充缓存，提高缓存命中率，防止缓存击穿</li><li>监听mysql canal消息主动刷新缓存</li><li>添加短时间内的本地缓存，行程二级缓存</li></ul></li></ul><h3 id="优化效果"><a href="#优化效果" class="headerlink" title="优化效果"></a>优化效果</h3><ul><li>API响应性能提升40%</li><li>缓存命中率97%以上</li><li>非核心查询的数据与写库延迟2s内，系统各项指标更平稳</li></ul><h3 id="经验总结"><a href="#经验总结" class="headerlink" title="经验总结"></a>经验总结</h3><ul><li>结合使用场景和数据特点进行设计</li><li>Key的设计  考虑加版本号</li><li>慎用跨应用缓存</li><li>慎用长时间的缓存</li><li>尽量不要缓存大对象</li><li>超短时间的本地缓存</li><li>留条后路 开关和刷缓存接</li></ul>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>elasticsearch学习系列-分布式系统中深度分页</title>
      <link href="/2020/01/11/elasticsearch-xue-xi-xi-lie-fen-bu-shi-xi-tong-zhong-shen-du-fen-ye/"/>
      <url>/2020/01/11/elasticsearch-xue-xi-xi-lie-fen-bu-shi-xi-tong-zhong-shen-du-fen-ye/</url>
      
        <content type="html"><![CDATA[<p>本文介绍下ES中搜索的分页功能，据此也引出分布式系统中深度分页的问题</p><h4 id="ES分页功能"><a href="#ES分页功能" class="headerlink" title="ES分页功能"></a>ES分页功能</h4><ul><li>elasticsearch接收form（开始返回的结果位置，从0开始）和size（返回的数量）参数；</li><li>结果集在返回之前先排序，每个分片产生自己的排序结果，再集中排序保证整体顺序；</li></ul><h4 id="深度分页"><a href="#深度分页" class="headerlink" title="深度分页"></a>深度分页</h4><ul><li>在分布式系统中，对结果排序的成本随分页的深度成指数上升；</li><li>例：如我们有10个分片，要获取第1000页的数据，默认size为10，则没个分片产生100010个数据，最后<br>对全部的1000100个结果排序并丢弃掉其中大部分的数据；</li><li>参考大部分web搜索引擎对任何查询都不返回过多的结果；</li></ul><h4 id="游标查询-scoll"><a href="#游标查询-scoll" class="headerlink" title="游标查询 scoll"></a>游标查询 scoll</h4><ul><li>es可使用scoll进行大批量的文档查询，而不需要付出深度分页的代价；</li><li>游标查询会取某个时间点的快照数据。 查询初始化之后索引上的任何变化会被它忽略。 它通过保存旧的数据文件来实现这个特性，结果就像保留初始化时的索引视图一样；</li><li>深度分页的代价根源是结果集全局排序，如果去掉全局排序的特性的话查询结果的成本就会很低。 游标查询用字段 _doc 来排序。这个指令让 Elasticsearch 仅仅从还有结果的分片返回下一批结果</li></ul>]]></content>
      
      
      <categories>
          
          <category> elasticsearch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> elasticsearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>记一次上线后服务器cpu飙升异常问题</title>
      <link href="/2020/01/11/ji-yi-ci-shang-xian-hou-fu-wu-qi-cpu-biao-sheng-yi-chang-wen-ti/"/>
      <url>/2020/01/11/ji-yi-ci-shang-xian-hou-fu-wu-qi-cpu-biao-sheng-yi-chang-wen-ti/</url>
      
        <content type="html"><![CDATA[<p>今天记录分享一次服务上线后cpu飙升问题</p><h3 id="问题经过和分析"><a href="#问题经过和分析" class="headerlink" title="问题经过和分析"></a>问题经过和分析</h3><ul><li>项目的场景是接收各个系统的消息进行处理，</li><li>项目消费上线前，一些发消息的业务逻辑先上线，消息在消息队列内大量挤压</li><li>服务上线，没有对消息队列内消息reset处理，大量消息涌入</li><li>服务内部并发处理的多线程备撑满，频繁gc（平均一分枝接近50次）</li><li>服务器cpu飙升，内存使用飙升，发出警报</li><li>取消消费开关，消息队列reset后正常</li></ul><h3 id="总结提醒"><a href="#总结提醒" class="headerlink" title="总结提醒"></a>总结提醒</h3><ul><li>系统上线前考虑好是否有潜在影响</li><li>设计时做好开关设计，异常情况下可以有效控制服务逻辑</li><li>尽量做好压测试</li></ul>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 问题记录 </tag>
            
            <tag> java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>elasticsearch升级-transportClient转HighLevelRestClient</title>
      <link href="/2020/01/02/elasticsearch-sheng-ji-transportclient-zhuan-highlevelrestclient/"/>
      <url>/2020/01/02/elasticsearch-sheng-ji-transportclient-zhuan-highlevelrestclient/</url>
      
        <content type="html"><![CDATA[<p>今天分享下项目中进行elasticsearch升级，同时伴随着transport Client转换位High Level Rest Client.</p><h3 id="升级迁移步骤"><a href="#升级迁移步骤" class="headerlink" title="升级迁移步骤"></a>升级迁移步骤</h3><ul><li>es 集群升级（DBA操作）</li><li>数据全量迁移</li><li>使用High Level Rest Client和transport Client对新老集群双写；</li><li>数据全量迁移</li><li>读改到升级后新集群</li><li>老集群断写入</li></ul><h3 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h3><p><img src="/images/es_jg.jpeg" alt="架构简介"></p><h3 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h3><ul><li>数据迁移过程中双写，并建立补偿机制，避免数据丢失</li><li>核心业务部署双集群，封装DR</li><li>建立db数据和es数据的全量同步流程，修复数据不一致</li></ul>]]></content>
      
      
      <categories>
          
          <category> elasticsearch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> elasticsearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>java虚拟机内存区域介绍</title>
      <link href="/2019/12/22/java-xu-ni-ji-nei-cun-qu-yu-jie-shao/"/>
      <url>/2019/12/22/java-xu-ni-ji-nei-cun-qu-yu-jie-shao/</url>
      
        <content type="html"><![CDATA[<p>本文将简单介绍下java内存区域，借此加深对java虚拟机的理解；<br>希望对入门者有一定的引导作用，同时也作为记录帮助自己记忆，若有错误，希望大牛指点一二；</p><h4 id="简述"><a href="#简述" class="headerlink" title="简述"></a>简述</h4><p>java虚拟机所管理的内存包括这几个运行时数据区：程序计数器、java虚拟机栈、本地方法栈、java堆、方法区、直接内存；<br>参考图片（来自《深入理解java虚拟机》，推荐阅读）：<br><img src="/images/jvm1.PNG" alt="java虚拟机运行时数据区"></p><h4 id="程序计数器"><a href="#程序计数器" class="headerlink" title="程序计数器"></a>程序计数器</h4><ul><li>当前线程所执行的字节码的行号指示器，根据这里的值来选取下一条需要执行的字节码指令；</li><li>每个线程都有一个程序计数器，各线程互不影响；</li></ul><h4 id="java虚拟机栈"><a href="#java虚拟机栈" class="headerlink" title="java虚拟机栈"></a>java虚拟机栈</h4><ul><li>线程私有的，线程间互不干扰，生命周期与线程相同；</li><li>描述java方法执行的内存模型，每个方法再执行时会建立一个栈帧用于存储局部变量表、操作数栈、动态连接、方法出口等信息；每个方法调用至完成就对应一个栈帧（栈帧是方法运行时的基础数据结构）再虚拟机栈中入栈到出栈的过程；</li><li>其中局部变量表存放了编译器可知的各种基本数据类型；</li><li>这个区域存在两种异常状况：StackOverflowError（线程请求的栈深度大于虚拟机允许深度）和OutOfMemoryError（扩展时无法申请足够内存）；</li></ul><h4 id="本地方法栈"><a href="#本地方法栈" class="headerlink" title="本地方法栈"></a>本地方法栈</h4><ul><li>与虚拟机栈作用相似， 为虚拟机使用的Native方法服务；</li><li>也会抛出StackOverflowError和OutOfMemoryError；</li></ul><h4 id="java堆"><a href="#java堆" class="headerlink" title="java堆"></a>java堆</h4><ul><li>java虚拟机管理内存中最大的一块， 是所有线程共享的一块内存区域；</li><li>用来存放对象实例；</li><li>是垃圾收集器管理的主要区域，又称为”GC堆”；</li><li>可分为新生代和老年代，再细分为Eden空间 From Survivor和To Survivor空间 ；</li><li>堆无法扩展时会抛出OutOfMemoryError异常；</li></ul><h4 id="方法区"><a href="#方法区" class="headerlink" title="方法区"></a>方法区</h4><ul><li>各个线程共享的内存区域；</li><li>存储虚拟机加载的类信息、常量、静态变量、编译后的代码等；</li><li>内存不满足时抛出OutOfMemoryError异常；</li></ul><h4 id="直接内存"><a href="#直接内存" class="headerlink" title="直接内存"></a>直接内存</h4><ul><li>内存不够会抛出OutOfMemoryError异常；</li><li>不是虚拟机运行时数据区的一部分；</li></ul><h4 id="对象创建"><a href="#对象创建" class="headerlink" title="对象创建"></a>对象创建</h4><ul><li>虚拟机遇到new指令，检查参数是否能在常量池中定位到类的符号引用，若没有，先执行类加载过程（该过程会在后续文章进行分享）；</li><li>类加载检查完，在java堆中为对象分配内存（受不同收集器影响）；</li><li>虚拟机对对象进行一些设置：是哪个类的实例，如何查找类元数据信息，对象哈希码，对象的GC分代年龄等；</li><li>执行init进行初始化；</li></ul><h4 id="对象的访问定位"><a href="#对象的访问定位" class="headerlink" title="对象的访问定位"></a>对象的访问定位</h4><ul><li>需要通过栈上的reference数据来操作栈上的对象；</li><li>两种访问方式：<ul><li>句柄：java堆种一块内存作为句柄池，reference保存对象的句柄地址，句柄再保存对象实例数据和类型数据的具体地址信息；</li><li>直接指针：java堆对象放置访问类型数据，reference种存储对象地址；</li></ul></li></ul><p>以上是对java虚拟机涉及内存以及对象创建、对象访问定位流程的简单介绍，后续会继续进行相关基础和进阶知识的学习整理分享，欢迎一起讨论交流~</p>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>java并发专题-线程池介绍</title>
      <link href="/2019/12/08/java-bing-fa-zhuan-ti-xian-cheng-chi-xiang-jie/"/>
      <url>/2019/12/08/java-bing-fa-zhuan-ti-xian-cheng-chi-xiang-jie/</url>
      
        <content type="html"><![CDATA[<p>今天介绍下java中的线程池应用，主要介绍java中的Excutor框架</p><h3 id="线程池的好处"><a href="#线程池的好处" class="headerlink" title="线程池的好处"></a>线程池的好处</h3><ul><li>提高响应速度，处理任务时无需等待线程创建；</li><li>提高线程管理性，对线程池内线程统一分配、调度、管理；</li><li>降低资源消耗，通过重复利用已创建的线程降低线程创建和销毁造成的消耗；</li></ul><h3 id="线程池的处理流程"><a href="#线程池的处理流程" class="headerlink" title="线程池的处理流程"></a>线程池的处理流程</h3><ul><li>线程池判断核心线程池里的线程是否都在执行任务。如果不是，则创建一个新的工作线程来执行任务。如果核心线程池里的线程都在执行任务，则进入下个流程</li><li>线程池判断工作队列是否已经满。如果工作队列没有满，则将新提交的任务存储在这个工作队列里。如果工作队列满了，则进入下个流程</li><li>线程池判断线程池的线程是否都处于工作状态。如果没有，则创建一个新的工作线程来执行</li></ul><h3 id="ThreadPoolExecutor详解"><a href="#ThreadPoolExecutor详解" class="headerlink" title="ThreadPoolExecutor详解"></a>ThreadPoolExecutor详解</h3><ul><li>ThreadPoolExecutor：<pre><code>new ThreadPoolExecutor(int corePoolSize,                int maximumPoolSize,                long keepAliveTime,                TimeUnit unit,                BlockingQueue&lt;Runnable&gt; workQueue,                ThreadFactory threadFactory,                RejectedExecutionHandler handler)</code></pre><ul><li>corePoolSize: 当提交一个任务到线程池时，线程池会创建一个线程来执行任务，即使其他空闲的基本线程能够执行新任务也会创建线程，等到需要执行的任务数大于线程池corePoolSize大小时就不再创建；</li><li>maximumPoolSize： 线程池允许创建的最大线程数。如果队列满了，并且已创建的线程数小于最大线程数，则线程池会再创建新的线程执行任务。值得注意的是，如果使用了无界的任务队列这个参数就没什么效果;</li><li>keepAliveTime：线程最大空闲时间</li><li>TimeUnit：时间单位</li><li>workQueue：用于保存等待执行的任务队列；（下方详细介绍）</li><li>threadFactory： 用于设置创建线程的工厂，可以通过线程工厂给每个创建出来的线程设置更有意义的名字；</li><li>handler：当队列和线程池都满了，说明线程池处于饱和状态，那么必须采取一种策略处理提交的新任务（下方详细介绍）</li></ul></li><li>FixedThreadPool<pre><code>   new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;())</code></pre><ul><li>FixedThreadPool的corePoolSize和maximumPoolSize都被设置为创建FixedThreadPool时指定的参数nThreads</li><li>如果当前运行的线程数少于corePoolSize，则创建新线程来执行任务</li><li>在线程池完成预热之后（当前运行的线程数等于corePoolSize），将任务加入LinkedBlockingQueue</li><li>线程执行完1中的任务后，会在循环中反复从LinkedBlockingQueue获取任务来执行</li><li>FixedThreadPool使用无界队列LinkedBlockingQueue作为线程池的工作队列（队列的容量为Integer.MAX_VALUE）,所以maximumPoolSize是一个无效参数，线程池的线程数量不超过corePoolSize，有oom风险</li></ul></li><li>SingleThreadExecutor<pre><code>new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;())</code></pre><ul><li>SingleThreadExecutor的corePoolSize和maximumPoolSize被设置为1</li><li>其他参数与FixedThreadPool相同</li></ul></li><li>CachedThreadPool<pre><code>new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;())</code></pre><ul><li>CachedThreadPool的corePoolSize被设置为0，即corePool为空；maximumPoolSize被设置为Integer.MAX_VALUE，即maximumPool是无界的</li><li>keepAliveTime设置为60L，意味着CachedThreadPool中的空闲线程等待新任务的最长时间为60秒，空闲线程超过60秒后将会被终止</li><li>CachedThreadPool使用没有容量的SynchronousQueue作为线程池的工作队列，但CachedThreadPool的maximumPool是无界的。这意味着，如果主线程提交任务的速度高于maximumPool中线程处理任务的速度时，CachedThreadPool会不断创建新线程(极端情况下，CachedThreadPool会因为创建过多线程而耗尽CPU和内存资源)</li></ul></li><li>线程等待队列<ul><li>直接提交： 工作队列的默认选项是 SynchronousQueue，它将任务直接提交给线程而不保持它们。在此，如果不存在可用于立即运行任务的线程，则试图把任务加入队列将失败，因此会构造一个新的线程。此策略可以避免在处理可能具有内部依赖性的请求集时出现锁。直接提交通常要求无界 maximumPoolSizes 以避免拒绝新提交的任务。当命令以超过队列所能处理的平均数连续到达时，此策略允许无界线程具有增长的可能性；</li><li>无界队列： 使用无界队列（例如，不具有预定义容量的 LinkedBlockingQueue）将导致在所有 corePoolSize 线程都忙时新任务在队列中等待。这样，创建的线程就不会超过 corePoolSize。（因此，maximumPoolSize 的值也就无效了。）当每个任务完全独立于其他任务，即任务执行互不影响时，适合于使用无界队列；例如，在 Web 页服务器中。这种排队可用于处理瞬态突发请求，当命令以超过队列所能处理的平均数连续到达时，此策略允许无界线程具有增长的可能性</li><li>有界队列：当使用有限的 maximumPoolSizes 时，有界队列（如 ArrayBlockingQueue）有助于防止资源耗尽，但是可能较难调整和控制。队列大小和最大池大小可能需要相互折衷：使用大型队列和小型池可以最大限度地降低 CPU 使用率、操作系统资源和上下文切换开销，但是可能导致人工降低吞吐量。如果任务频繁阻塞（例如，如果它们是 I/O 边界），则系统可能为超过您许可的更多线程安排时间。使用小型队列通常要求较大的池大小，CPU 使用率较高，但是可能遇到不可接受的调度开销，这样也会降低吞吐量</li></ul></li><li>决绝策略<ul><li>AbortPolicy：直接抛出异常；</li><li>CallerRunsPolicy：只用调用者所在线程来运行任务；</li><li>DiscardPolicy：不处理，丢弃掉；</li><li>DiscardOldestPolicy：丢弃队列里最近的一个任务，并执行当前任务；</li></ul></li></ul><h3 id="ScheduledThreadPoolExecutor介绍"><a href="#ScheduledThreadPoolExecutor介绍" class="headerlink" title="ScheduledThreadPoolExecutor介绍"></a>ScheduledThreadPoolExecutor介绍</h3><ul><li>ScheduledThreadPoolExecutor运动介绍<ul><li>使用DelayQueue是一个无界队列，所以ThreadPoolExecutor的maximumPoolSize在Scheduled-ThreadPoolExecutor中没有意义;</li><li>当调用ScheduledThreadPoolExecutor的scheduleAtFixedRate()方法或者scheduleWith-FixedDelay()方法时，会向ScheduledThreadPoolExecutor的DelayQueue添加一个实现了RunnableScheduledFutur接口的ScheduledFutureTask</li><li>线程池中的线程从DelayQueue中获取ScheduledFutureTask，然后执行任务</li></ul></li><li>ScheduledThreadPoolExecutor实现<ul><li>DelayQueue封装了一个PriorityQueue，这个PriorityQueue会对队列中的Scheduled-FutureTask进行排序。排序时，time小的排在前面（时间早的任务将被先执行）。如果两个ScheduledFutureTask的time相同，就比较sequenceNumber，sequenceNumber小的排在前面</li><li>线程执行周期任务<ul><li>线程从DelayQueue中获取已到期的ScheduledFutureTask（DelayQueue. take()）。到期任务是指ScheduledFutureTask的time大于等于当前时间</li><li>线程执行这个ScheduledFutureTask</li><li>线程修改ScheduledFutureTask的time变量为下次将要被执行的时间</li><li>线程把这个修改time之后的ScheduledFutureTask放回DelayQueue中（Delay-Queue.add())</li></ul></li><li>获取任务<ul><li>获取Lock</li><li>获取周期任务</li><li>释放Lock</li></ul></li><li>添加任务 类似获取任务</li></ul></li></ul><h3 id="特别提醒"><a href="#特别提醒" class="headerlink" title="特别提醒"></a>特别提醒</h3><ul><li>使用new ThreadPoolExecutor自行创建线程池，更好的管理线程数，队列，避免使用中存在无界问题导致oom；</li><li>线程池消耗一定的系统资源，结合实际避免创建过多线程池，如创建static 线程池</li></ul>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java </tag>
            
            <tag> 并发 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>记一次线上问题-java内存溢出</title>
      <link href="/2019/11/08/ji-yi-ci-xian-shang-wen-ti-java-nei-cun-yi-chu/"/>
      <url>/2019/11/08/ji-yi-ci-xian-shang-wen-ti-java-nei-cun-yi-chu/</url>
      
        <content type="html"><![CDATA[<p>这里分享一个线上问题案例及解决过程。<br>小k来到新公司不久，一天早上，小K收到一封报警邮件，提示某项目出现较多异常。小k点击邮件查看详情，发现提示out of menery错误。此时同事们还没来，小k暗自吐槽：“怎么都没来，这个项目代码自己也还不熟悉阿”。但是小k转念一想：“毕竟也是有2年开发经验的人，自己先排查下吧”<br>&nbsp;<br>于是小k开始查看日志系统，发现报错基本集中在个别机器上。小k打开该项目的机器监控，发现有两台机器的内存使用率高于正常水平。进一步发现这两台机器的线程数量远高于其他机器以及此前的正常水平。<br>&nbsp;<br><img src="/images/3.png" alt="服务内存监控（此为正常情况，异常是超过90%）"><br><img src="/images/4.png" alt="线程监控（此为正常情况，异常机器的JMX thread数量有个梯度上升）"><br>小k心中有了方向，进一步针对机器的线程收集监控，获取到异常机器的大量线程来自同一个线程池。此时小k的组长大M来了，小k把相关问题以及排查结果向大M进行了说明，大M找到项目中使用该线程池的地方，小k暗叹：“还是对项目熟悉定位问题比较快哇”。然后两个人一起看起了代码。不一会，就发现了问题，当然代码的创造者早已离开。<br>关键代码如下：</p><pre><code>ExecutorService executor = Executors.newFixedThreadPool(size);</code></pre><p>问题在于这里的size是会根据请求中某参数的数量动态创建的。原先的的请求内参数并没有特别多，创建了定长线程池执行完后可以安全释放。但是现在遇到两个参数过多的请求（并没有对请求方限制批量处理的的数量），导致创建过多线程消耗过多内存，程序异常，也无法执行下面的对线程池的回收和销毁。<br>&nbsp;<br>确定了问题之后，组长让我对这里进行了修改，添加了创建线程数量的限制，防止线程泄露。上线后项目也恢复了正常。<br>&nbsp;<br>小k在这次问题排查中学到了很多：</p><ol><li>创建线程池本身要注意，要合理限制创建线程的最大数量，防止消耗过多的资源；</li><li>线程池使用中要确保在正常和异常情况下对线程池进行释放；</li><li>批量接口最好对最大请求数量进行约定和限制，防止不可控的异常；<br>小k整理了下思路，继续开始一天愉快得工作，直到深夜….</li></ol>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 问题记录 </tag>
            
            <tag> java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>java容器-列表和队列</title>
      <link href="/2019/11/05/java-rong-qi-lie-biao-he-dui-lie/"/>
      <url>/2019/11/05/java-rong-qi-lie-biao-he-dui-lie/</url>
      
        <content type="html"><![CDATA[<p>今天介绍一些java内的容器-列表和队列，有些容器会在后续案例中更详细介绍</p><h3 id="列表和队列"><a href="#列表和队列" class="headerlink" title="列表和队列"></a>列表和队列</h3><ul><li>ArrayList<ul><li>实现了Iterable接口，可迭代，</li><li>内部有一个数组elementData，一般有些预留空间，有整数size记录实际元素个数；</li><li>添加元素时先判断数组是不是空的，如果是空的，则首次至少要分配的大小为DEFAULT_CAPACITY,DEFAULT_CAPACITY的值为10;</li><li>有以指定的大小initialCapacity初始化内部的数组大小的构造方法</li><li>可以随机访问，按照索引位置进行访问效率很高，用算法描述中的术语，效率是O(1)，简单说就是可以一步到位</li><li>除非数组已排序，否则按照内容查找元素效率比较低，具体是O(N), N为数组内容长度，也就是说，性能与数组长度成正比</li><li>添加元素的效率还可以，重新分配和复制数组的开销被平摊了，具体来说，添加N个元素的效率为O(N)</li><li>插入和删除元素的效率比较低，因为需要移动元素，具体为O(N)</li><li>非线程安全的</li></ul></li><li>LinkedList<ul><li>实现了Deque和Queue接口，可以按照队列、栈和双端队列的方式进行操作</li><li>内部实现是双向链表，每个元素在内存都是单独存放的，元素之间通过链接连在一起</li><li>按需分配空间，不需要预先分配很多空间</li><li>不可以随机访问，按照索引位置访问效率比较低，必须从头或尾顺着链接找，效率为O(N/2)</li><li>不管列表是否已排序，只要是按照内容查找元素，效率都比较低，必须逐个比较，效率为O(N)</li><li>在两端添加、删除元素的效率很高，为O(1</li><li>在中间插入、删除元素，要先定位，效率比较低，为O(N)，但修改本身的效率很高，效率为O(1)</li></ul></li><li>ArrayDeque<ul><li>基于数组实现</li><li>ArrayDeque实现了Deque接口，同LinkedList一样，它的队列长度也是没有限制的</li><li>ArrayDeque的高效来源于head和tail这两个变量，它们使得物理上简单的从头到尾的数组变为了一个逻辑上循环的数组，避免了在头尾操作时的移动</li><li>在两端添加、删除元素的效率很高，动态扩展需要的内存分配以及数组复制开销可以被平摊，具体来说，添加N个元素的效率为O(N)</li><li>根据元素内容查找和删除的效率比较低，为O(N)</li><li>与ArrayList和LinkedList不同，没有索引位置的概念，不能根据索引位置进行操作</li></ul></li></ul><h3 id="特别说明"><a href="#特别说明" class="headerlink" title="特别说明"></a>特别说明</h3><ul><li>关于迭代器，有一种常见的误用，就是在迭代的中间调用容器的删除方法，如<pre><code>for(Integer a : list) {  if(a&lt;=0) {    list.remove(a);  }}</code></pre>会抛出一场，可以改用迭代器：<pre><code>Iterator&lt;Integer&gt; it = list.iterator();while(it.hasNext()) {if(it.next() &lt; 0) {  it.remove();}}</code></pre>原理： 迭代器中cursor表示下一个要返回的元素位置，lastRet表示最后一个返回的索引位置，expected-ModCount表示期望的修改次数，初始化为外部类当前的修改次数modCount，回顾一下，成员内部类可以直接访问外部类的实例变量。每次发生结构性变化的时候modCount都会增加，而每次迭代器操作的时候都会检查expectedModCount是否与modCount相同，这样就能检测出结构性变化</li><li>多线程并发场景下，需要选择线程安全的容器，如ArrayList就不是线程安全的，直接在并发场景使用会有问题</li></ul>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>缓存数据一致性刷新方案</title>
      <link href="/2019/10/31/huan-cun-shu-ju-yi-zhi-xing-shua-xin-fang-an/"/>
      <url>/2019/10/31/huan-cun-shu-ju-yi-zhi-xing-shua-xin-fang-an/</url>
      
        <content type="html"><![CDATA[<p>这里分享一下缓存和数据库数据一致性刷新的一些方案和实践。<br>主要从一下4个方面进行介绍和分享。</p><h4 id="数据一致性介绍"><a href="#数据一致性介绍" class="headerlink" title="数据一致性介绍"></a>数据一致性介绍</h4><ul><li>随着业务发展，数据需要添加副本以提高可行性；</li><li>为减少db访问压力，需要进行读写分离；</li><li>为提高接口响应时间，一般会将访问数据进行缓存；</li><li>当然还有其他形式的数据，如存储与es搜索引擎以满足特定业务场景（此处主要讨论缓存数据一致性）；</li></ul><h4 id="一些方案"><a href="#一些方案" class="headerlink" title="一些方案"></a>一些方案</h4><ul><li>使用缓存的一些场景：<ul><li>面向用户的接口请求量大，使用缓存提升性能；</li><li>数据强一致性场景（如 库存），直接操作数据库，展示类接口使用缓存；</li></ul></li><li>方案一：<ul><li>查询接口时无缓存数据进行缓存数据的写入；</li><li>缓存失效时间使缓存自动失效；</li><li>数据变动，根据对db从库的监听对缓存进行失效；</li></ul></li><li>方案二：<ul><li>查询接口时无缓存则获取缓存；</li><li>缓存自动失效；</li><li>数据变动触发缓存数据更新；</li></ul></li></ul><h4 id="遇到的问题和解决"><a href="#遇到的问题和解决" class="headerlink" title="遇到的问题和解决"></a>遇到的问题和解决</h4><ul><li>问题：从数据库变动发出消息失效缓存，写入缓存时读取其他从库，导致写入脏数据；<ul><li>解决：所有的从库数据变动都去发送触发缓存失效的消息；<br><img src="/images/多线程缓存读写1.png" alt="多线程缓存读写1"></li></ul></li><li>问题：过期缓存删除存在隐患，无法预知当前是否有线程已持有过期数据正要插入（缓存的读取不是原子操作）；如下图：<ul><li>解决：采用如下图的方案：相关说明如下<br><img src="/images/多线程缓存读写2.png" alt="多线程缓存读写2"></li><li>先删除缓存后删除db数据，防止当前网站线程crash引起数据不一致；</li><li>原子操作前判断缓存是否命中，命中则直接返回，防止热点数据引起的缓存击穿；</li><li>减小缓存数据的颗粒，减小此处锁的颗粒，降低锁开销，锁持有的时间就是一次数据库访问的时间；</li></ul></li></ul><h4 id="一些思考和总结"><a href="#一些思考和总结" class="headerlink" title="一些思考和总结"></a>一些思考和总结</h4><ul><li>任何技术方案都需要根据具体的业务场来考虑，比如缓存方案中，数据变动是去时缓存失效还是刷新缓存，就是可以考虑多个方面；</li><li>缓存多大范围的数据？</li><li>数据的热点程度？</li></ul>]]></content>
      
      
      <categories>
          
          <category> redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>java容器-堆和优先队列</title>
      <link href="/2019/10/16/java-rong-qi-dui-he-you-xian-dui-lie/"/>
      <url>/2019/10/16/java-rong-qi-dui-he-you-xian-dui-lie/</url>
      
        <content type="html"><![CDATA[<p>今天介绍一些java内的容器-堆和优先队列，有些容器会在后续案例中更详细介绍</p><h3 id="堆"><a href="#堆" class="headerlink" title="堆"></a>堆</h3><ul><li>是完全二叉树，给定任意一个节点，可以根据其编号直接快速计算出其父节点和孩子节点编号</li><li>根据顺序分为两种堆：一种是最大堆，另一种是最小堆</li><li>可以实现优先级队列，解决求前K个最大的元素，求中值元素等问题</li><li>堆还可以实现排序，称之为堆排序</li><li>概念上是树，存储为数组，父子有特殊顺序，根是最大值/最小值，构建/添加/删除效率都很高</li></ul><h3 id="优先队列"><a href="#优先队列" class="headerlink" title="优先队列"></a>优先队列</h3><ul><li>PriorityQueue<ul><li>内部是用堆实现的，内部元素不是完全有序的，逐个出队会得到有序的输出</li><li>优先级可以有相同的，内部元素不是完全有序的，如果遍历输出，除了第一个，其他没有特定顺序</li><li>查看头部元素的效率很高，为O(1)，入队、出队效率比较高，为O(log2(N))，构建堆heapify的效率为O(N)</li></ul></li></ul><h3 id="特别说明"><a href="#特别说明" class="headerlink" title="特别说明"></a>特别说明</h3><ul><li>对于某些问题（如求前k个最大元素和求中值），相比使用排序，使用堆不仅实现效率更高，而且可以应对数据量不确定且源源不断到来的情况，可以给出实时结果</li></ul>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>java容器-Map和Set</title>
      <link href="/2019/10/15/java-rong-qi-map-he-set/"/>
      <url>/2019/10/15/java-rong-qi-map-he-set/</url>
      
        <content type="html"><![CDATA[<p>今天介绍一些java内的容器-Map和Set，有些容器会在后续案例中更详细介绍</p><h3 id="Map"><a href="#Map" class="headerlink" title="Map"></a>Map</h3><ul><li>HashMap<ul><li>实现map接口， key value键值对</li><li>内部实例变量size表示实际键值对的个数。table是一个Entry类型的数组，称为哈希表或哈希桶，其中的每个元素指向一个单向链表，链表中的每个节点表示一个键值对，Entry是一个内部类，其中，key和value分别表示键和值，next指向下一个Entry节点，hash是key的hash值；</li><li>扩展策略： threshold表示阈值，当键值对个数size大于等于threshold时考虑进行扩展， 一般而言，threshold等于table.length乘以loadFactor，会分配一个容量为原来两倍的Entry数组，调用transfer方法将原来的键值对移植过来，然后更新内部的table变量，以及threshold的值</li><li>key比较的时候，是先比较hash值，hash相同的时候，再使用equals方法进行比较，要求元素重写hashCode和equals方法</li><li>保存键值对的流程：<ul><li>计算键哈希值</li><li>根据哈希值取得保存位置</li><li>插到对应位置的链表头部或更新已有值</li><li>根据需要扩展table大小</li></ul></li><li>分配一个容量为原来两倍的Entry数组，调用transfer方法将原来的键值对移植过来，然后更新内部的table变量，以及threshold的值</li><li>hash值是随即的，键值对没有顺序</li></ul></li><li>TreeSet<ul><li>按键有序，TreeMap同样实现了SortedMap和NavigableMap接口，可以方便地根据键的顺序进行查找，如第一个、最后一个、某一范围的键、邻近键等,要求键实现Comparable接口或通过构造方法提供一个Com-parator对象</li><li>内部是用红黑树实现的，红黑树是一种大致平衡的排序二叉树</li><li>根据键保存、查找、删除的效率比较高，为O(h), h为树的高度，在树平衡的情况下，h为log2(N), N为节点数</li></ul></li><li>LinkedHashMap<ul><li>是HashMap的子类，内部还有一个双向链表维护键值对的顺序，每个键值对既位于哈希表中，也位于这个双向链表中。</li><li>LinkedHashMap支持两种顺序：一种是插入顺序；另外一种是访问顺序； （按访问有序-LRU缓存）</li></ul></li></ul><h3 id="Set"><a href="#Set" class="headerlink" title="Set"></a>Set</h3><ul><li>hashSet<ul><li>没有重复元素</li><li>可以高效地添加、删除元素、判断元素是否存在，效率都为O(1)</li><li>无序</li><li>要求元素重写hashCode和equals方法，且对于两个对象，如果equals相同，则hashCode也必须相同</li><li>内部是用HashMap实现的</li></ul></li><li>TreeSet<ul><li>有序</li><li>给予TreeMap实现</li><li>添加、删除元素、判断元素是否存在，效率比较高，为O(log2(N)), N为元素个数</li><li>TreeSet同样实现了SortedSet和NavigatableSet接口，可以方便地根据顺序进行查找和操作，如第一个、最后一个、某一取值范围、某一值的邻近元素等，要求元素实现Comparable接口或通过构造方法提供一个Com-parator对象</li></ul></li><li>LinkedHashSet<ul><li>内部的Map的实现类是LinkedHashMap</li></ul></li></ul><h3 id="特别说明"><a href="#特别说明" class="headerlink" title="特别说明"></a>特别说明</h3><ul><li>HashMap也不是线程安全的，并发场景下需要注意，可以使用HashTable，但是相应效率地下，可以使用ConcurrentHashMap，兼顾性能和并发</li><li>map的keySet和entrySet返回都是set，所以一般可以用map实现对应的set；</li></ul>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分布式系统中的一些设计策略</title>
      <link href="/2019/10/13/fen-bu-shi-xi-tong-zhong-de-yi-xie-she-ji-ce-lue/"/>
      <url>/2019/10/13/fen-bu-shi-xi-tong-zhong-de-yi-xie-she-ji-ce-lue/</url>
      
        <content type="html"><![CDATA[<p>今天介绍分布式系统下的一些通用的设计策略</p><h3 id="心跳检测"><a href="#心跳检测" class="headerlink" title="心跳检测"></a>心跳检测</h3><ul><li>多个节点分担任务的运行、计算或者程序逻辑处理，需要检测一个节点出现了故障乃至无法工作</li><li>可使用周期检测心跳机制、累计失效检测机制</li><li>周期检测心跳机制：Server端每间隔t秒向Node集群发起监测请求，设定超时时间，如果超过超时时间，则判断“死亡”。这里的超时时间设置带有随意性，容易误判。进一步，可以统计实际检测Node的返回时间，包括得到一定周期内的最长时间。那么可以根据现有没有正确返回的时间在历史统计的分布中计算得到“死亡”概率，同时对于宣告濒临死亡的节点可以发起有限次数的重试，以作进一步判定。心跳检测本身也是有效资源利用和成本之间的一种权衡，如果迟迟不能判断节点是否“死亡”，会影响业务逻辑的处理</li></ul><h3 id="高可用设计"><a href="#高可用设计" class="headerlink" title="高可用设计"></a>高可用设计</h3><ul><li>主备模式：当主机宕机时，备机接管主机的一切工作，待主机恢复正常后，按使用者的设定以自动（热备）或手动（冷备）方式将服务切换到主机上运行</li><li>互备模式：指两台主机同时运行各自的服务工作且相互监测情况。在数据库高可用部分，常见的互备是MM模式。MM模式即Multi-Master模式，指一个系统存在多个master，每个master都具有read-write能力，需根据时间戳或业务逻辑合并版本。比如分布式版本管理系统git可以理解成multi-master模式，具备最终一致性</li><li>集群模式：集群模式是指有多个节点在运行，同时可以通过主控节点分担服务请求，比如zookeeper。集群模式要特别解决主控节点本身的高可用问题</li></ul><h3 id="容错性"><a href="#容错性" class="headerlink" title="容错性"></a>容错性</h3><ul><li>容错的处理是保障分布式环境下相应系统的高可用或者健壮性，如缓存的雪崩问题</li></ul><h3 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h3><ul><li>关键在于使用多台集群服务器共同分担计算任务，把网络请求及计算分配到集群可用服务器上去，从而达到可用性及较好的用户操作体验</li><li>一些策略：<ul><li>轮询：即Round Robin，根据Nginx配置文件中的顺序，依次把客户端的Web请求分发到不同的后端服务器</li><li>最少连接：当前谁连接最少，分发给谁</li><li>IP地址哈希：确定相同IP请求可以转发给同一个后端节点处理，以方便session保持</li><li>基于权重的负载均衡：配置Nginx把请求更多地分发到高配置的后端服务器上，把相对较少的请求分发到低配服务器</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> 分布式系统 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分布式系统 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mysql-innodb存储引擎中的锁</title>
      <link href="/2019/08/15/mysql-innodb-cun-chu-yin-qing-zhong-de-suo/"/>
      <url>/2019/08/15/mysql-innodb-cun-chu-yin-qing-zhong-de-suo/</url>
      
        <content type="html"><![CDATA[<p>今天介绍下mysql innodb中的锁</p><h3 id="锁类型介绍（行级锁）"><a href="#锁类型介绍（行级锁）" class="headerlink" title="锁类型介绍（行级锁）"></a>锁类型介绍（行级锁）</h3><ul><li>共享锁（S）：允许事务读一行数据</li><li>排他锁（X）：允许事务删除或更新一行数据</li><li>如果一个事务T1已经获得了行r的共享锁，那么另外的事务T2可以立即获得行r的共享锁，因为读取并没有改变行r的数据，称这种情况为锁兼容，如X与X、S不兼容， S与X不兼容，S与S兼容；</li><li>InnoDB存储引擎支持多粒度（granular）锁定，这种锁定允许事务在行级上的锁和表级上的锁同时存在。为了支持在不同粒度上进行加锁操作，InnoDB存储引擎支持一种额外的锁方式，称之为意向锁（Intention Lock）。意向锁是将锁定的对象分为多个层次，意向锁意味着事务希望在更细粒度（fine granularity）上进行加锁</li></ul><h3 id="一致性非锁定读"><a href="#一致性非锁定读" class="headerlink" title="一致性非锁定读"></a>一致性非锁定读</h3><ul><li>InnoDB存储引擎通过行多版本控制（multi versioning）的方式来读取当前执行时间数据库中行的数据</li><li>如果读取的行正在执行DELETE或UPDATE操作，这时读取操作不会因此去等待行上锁的释放。相反地，InnoDB存储引擎会去读取行的一个快照数据</li><li>非锁定读不需要等待访问的行上X锁的释放。快照数据是指该行的之前版本的数据，该实现是通过undo段来完成。而undo用来在事务中回滚数据，因此快照数据本身是没有额外的开销。此外，读取快照数据是不需要上锁的，因为没有事务需要对历史的数据进行修改操作</li><li>非锁定读机制极大地提高了数据库的并发性。在InnoDB存储引擎的默认设置下，这是默认的读取方式，即读取不会占用和等待表上的锁。但是在不同事务隔离级别下，读取的方式不同，并不是在每个事务隔离级别下都是采用非锁定的一致性读。此外，即使都是使用非锁定的一致性读，但是对于快照数据的定义也各不相同</li><li>在事务隔离级别READ COMMITTED和REPEATABLE READ（InnoDB存储引擎的默认事务隔离级别）下，InnoDB存储引擎使用非锁定的一致性读。然而，对于快照数据的定义却不相同。在READ COMMITTED事务隔离级别下，对于快照数据，非一致性读总是读取被锁定行的最新一份快照数据。而在REPEATABLE READ事务隔离级别下，对于快照数据，非一致性读总是读取事务开始时的行数据版本</li></ul><h3 id="一致性锁定读"><a href="#一致性锁定读" class="headerlink" title="一致性锁定读"></a>一致性锁定读</h3><ul><li>在默认配置下，即事务的隔离级别为REPEATABLE READ模式下，InnoDB存储引擎的SELECT操作使用一致性非锁定读。</li><li>但是在某些情况下，用户需要显式地对数据库读取操作进行加锁以保证数据逻辑的一致性。而这要求数据库支持加锁语句，即使是对于SELECT的只读操作</li></ul><h3 id="自增长与锁"><a href="#自增长与锁" class="headerlink" title="自增长与锁"></a>自增长与锁</h3><ul><li>自增长在数据库中是非常常见的一种属性，也是很多DBA或开发人员首选的主键方式。在InnoDB存储引擎的内存结构中，对每个含有自增长值的表都有一个自增长计数器（auto-increment counter</li><li>插入操作会依据这个自增长的计数器值加1赋予自增长列。这个实现方式称做AUTO-INCLocking。这种锁其实是采用一种特殊的表锁机制，为了提高插入的性能，锁不是在一个事务完成后才释放，而是在完成对自增长值插入的SQL语句后立即释放</li><li>从MySQL 5.1.22版本开始，InnoDB存储引擎中提供了一种轻量级互斥量的自增长实现机制，这种机制大大提高了自增长值插入的性能</li><li>需要注意InnoDB存储引擎中自增长的实现和MyISAM不同，MyISAM存储引擎是表锁设计，自增长不用考虑并发插入的问题。因此在master上用InnoDB存储引擎，在slave上用MyISAM存储引擎的replication架构下，必须考虑这种情况</li><li>在InnoDB存储引擎中，自增长值的列必须是索引，同时必须是索引的第一个列</li></ul><h3 id="外键与锁"><a href="#外键与锁" class="headerlink" title="外键与锁"></a>外键与锁</h3><ul><li>外键主要用于引用完整性的约束检查，在InnoDB存储引擎中，对于一个外键列，如果没有显式地对这个列加索引，InnoDB存储引擎自动对其加一个索引</li></ul>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>qmq消息队列-架构学习</title>
      <link href="/2019/07/19/qmq-xiao-xi-dui-lie-jia-gou-xue-xi/"/>
      <url>/2019/07/19/qmq-xiao-xi-dui-lie-jia-gou-xue-xi/</url>
      
        <content type="html"><![CDATA[<p>今天分享下qmq的架构</p><h3 id="组件介绍"><a href="#组件介绍" class="headerlink" title="组件介绍"></a>组件介绍</h3><ul><li>meta server: 提供集群管理和集群发现的作用</li><li>server: 提供实时消息服务</li><li>delay server: 提供延时/定时消息服务，延时消息先在delay server排队，时间到之后再发送给server</li><li>producer: 消息生产者</li><li>consumer： 消息消费者</li></ul><h3 id="交互过程"><a href="#交互过程" class="headerlink" title="交互过程"></a>交互过程</h3><p><img src="/images/qmq_jg.png" alt="qmq交互图"></p><ol><li>delay server 向meta server注册</li><li>实时server 向meta server注册</li><li>producer在发送消息前需要询问meta server获取server list</li><li>meta server返回server list给producer(根据producer请求的消息类型返回不同的server list)</li><li>producer发送延时/定时消息</li><li>延时时间已到，delay server将消息投递给实时server</li><li>producer发送实时消息</li><li>consumer需要拉取消息，在拉取之前向meta server获取server list(只会获取实时server的list)</li><li>meta server返回server list给consumer</li><li>consumer向实时server发起pull请求</li><li>实时server将消息返回给consumer</li></ol><h3 id="实时消息介绍"><a href="#实时消息介绍" class="headerlink" title="实时消息介绍"></a>实时消息介绍</h3><ul><li>QMQ没有采用基于partition存储模型，学习了很多Kafka和RocketMQ的存储实现方式：<ul><li>顺序append文件，提供很好的性能</li><li>顺序消费文件，使用offset表示消费进度，成本极低</li><li>将所有subject的消息合并在一起，减少parition数量，可以提供更多的subject(RocketMQ)</li></ul></li><li>通过添加一层拉取的log(pull log)来动态映射consumer与partition的逻辑关系，这样不仅解决了consumer的动态扩容缩容问题，还可以继续使用一个offset表示消费进度</li><li>时Server存储模型中有三种重要的log，消费者就可以使用pull log上的sequence来表示消费进度<ul><li>message log 所有subject的消息进入该log，消息的主存储</li><li>consume log consume log存储的是message log的索引信息</li><li>pull log 每个consumer拉取消息的时候会产生pull log，pull log记录的是拉取的消息在consume log中的sequence</li></ul></li></ul><h3 id="延时-定时消息介绍"><a href="#延时-定时消息介绍" class="headerlink" title="延时/定时消息介绍"></a>延时/定时消息介绍</h3><ul><li>QMQ提供任意时间的延时/定时消息，你可以指定消息在未来两年内(可配置)任意时间内投递。比起RocketMQ提供的多个不同延时level的延时消息，QMQ的延时消息更加灵活。比如在OTA场景中，客人经常是预订未来某个时刻的酒店或者机票，这个时间是不固定的，我们无法使用几个固定的延时level来实现这个场景</li><li>QMQ的延时/定时消息使用的是两层hash wheel来实现的。第一层位于磁盘上，每个小时为一个刻度(默认为一个小时一个刻度，可以根据实际情况在配置里进行调整)，每个刻度会生成一个日志文件(schedule log)，因为QMQ支持两年内的延迟消息(默认支持两年内，可以进行配置修改)，则最多会生成 2 <em> 366 </em> 24 = 17568 个文件(如果需要支持的最大延时时间更短，则生成的文件更少)。第二层在内存中，当消息的投递时间即将到来的时候，会将这个小时的消息索引(索引包括消息在schedule log中的offset和size)从磁盘文件加载到内存中的hash wheel上，内存中的hash wheel则是以500ms为一个刻度</li><li>在延时/定时消息里存在三种log<ul><li>message log 和实时消息里的message log类似，收到消息后append到该log就返回给producer，相当于WAL</li><li>schedule log 按照投递时间组织，每个小时一个。该log是回放message log后根据延时时间放置对应的log上，这是上面描述的两层hash wheel的第一层，位于磁盘上。schedule log里是包含完整的消息内容的，因为消息内容从message log同步到了schedule log，所以历史message log都可以删除(所以message log只需要占用极小的存储空间，所以我们可以使用低容量高性能的ssd来获取极高的吞吐量，比如采用100G极好的SSD只需要RMB2000左右)。另外，schedule log是按照延时时间组织的，所以延时时间已过的schedule log文件也可以删除</li><li>dispatch log 延时/定时消息投递成功后写入，主要用于在应用重启后能够确定哪些消息已经投递，dispatch log里写入的是消息的offset，不包含消息内容。当延时server中途重启时，我们需要判断出当前这个刻度(比如一个小时)里的消息有哪些已经投递了则不重复投递</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> qmq </category>
          
      </categories>
      
      
        <tags>
            
            <tag> qmq </tag>
            
            <tag> 消息队列 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>缓存策略-缓存算法介绍</title>
      <link href="/2019/07/12/huan-cun-ce-lue-huan-cun-suan-fa-jie-shao/"/>
      <url>/2019/07/12/huan-cun-ce-lue-huan-cun-suan-fa-jie-shao/</url>
      
        <content type="html"><![CDATA[<p>今天介绍下缓存算法</p><h3 id="FIFO算法"><a href="#FIFO算法" class="headerlink" title="FIFO算法"></a>FIFO算法</h3><ul><li>进先出（FIFO，队列），是最简单、最公平的一种思想，即如果一个数据是最先进入的，那么可以认为在将来它被访问的可能性很小。空间满的时候，最先进入的数据会被最早置换（淘汰）掉</li><li>实现：维护一个FIFO队列，按照时间顺序将各数据（已分配页面）链接起来组成队列，并将置换指针指向队列的队首。再进行置换时，只需把置换指针所指的数据（页面）顺次换出，并把新加入的数据插到队尾即可</li><li>缺点： FIFO算法会使一些页面频繁地被替换和重新申请内存，从而导致缺页率增加</li></ul><h3 id="LRU算法"><a href="#LRU算法" class="headerlink" title="LRU算法"></a>LRU算法</h3><ul><li>LRU（The Least Recently Used，最近最久未使用算法）是一种常见的缓存算法，在很多分布式缓存系统（如Redis, Memcached）中都有广泛使用</li><li>如果一个数据在最近一段时间没有被访问到，那么可以认为在将来它被访问的可能性也很小。因此，当空间满时，最久没有访问的数据最先被置换（淘汰）</li><li>实现：最朴素的思想就是用数组+时间戳的方式，不过这样做效率较低。因此，我们可以用双向链表（LinkedList）+哈希表（HashMap）实现（链表用来表示位置，哈希表用来存储和查找），在Java里有对应的数据结构LinkedHashMap</li></ul><h3 id="LFU算法"><a href="#LFU算法" class="headerlink" title="LFU算法"></a>LFU算法</h3><ul><li>LFU（Least Frequently Used ，最近最少使用算法）也是一种常见的缓存算法。思想是：如果一个数据在最近一段时间很少被访问到，那么可以认为在将来它被访问的可能性也很小。因此，当空间满时，最小频率访问的数据最先被淘汰</li><li>算法实现策略：考虑到 LFU 会淘汰访问频率最小的数据，我们需要一种合适的方法按大小顺序维护数据访问的频率。LFU 算法本质上可以看做是一个 top K 问题(K = 1)，即选出频率最小的元素，因此我们很容易想到可以用二项堆来选择频率最小的元素，这样的实现比较高效。最终实现策略为小顶堆+哈希表</li></ul>]]></content>
      
      
      <categories>
          
          <category> redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mysql-数据库隔离级别</title>
      <link href="/2019/07/07/mysql-shu-ju-ku-ge-chi-ji-bie/"/>
      <url>/2019/07/07/mysql-shu-ju-ku-ge-chi-ji-bie/</url>
      
        <content type="html"><![CDATA[<p>介绍下数据库隔离级别以及各隔离下的问题，以及mysql的默认隔离级别</p><h4 id="隔离级别"><a href="#隔离级别" class="headerlink" title="隔离级别"></a>隔离级别</h4><ul><li>Serializable：串行化<ul><li>强制事务排序，串行化读写，避免冲突</li></ul></li><li>Repeatable read：可重复读<ul><li>同一事务的多个实例在并发读取事务时，会“看到同样的”数据行</li></ul></li><li>Read committed：读已提交<ul><li>一个事务开始时，只能“看见”已经提交事务所做的改变</li><li>一个事务从开始到提交前，所做的任何数据改变都是不可见的，除非已经提交</li></ul></li><li>Read uncommitted：读未提交<ul><li>所有事务都可以“看到”未提交事务的执行结果</li></ul></li></ul><h4 id="各隔离级别下的问题"><a href="#各隔离级别下的问题" class="headerlink" title="各隔离级别下的问题"></a>各隔离级别下的问题</h4><p>见以下表格：</p><table><thead><tr><th>隔离级别 问题</th><th>脏读</th><th>不可重复读</th><th>幻读</th><th>加锁读</th></tr></thead><tbody><tr><td>Serializable</td><td>no</td><td>no</td><td>no</td><td>yes</td></tr><tr><td>Repeatable read</td><td>no</td><td>no</td><td>yes</td><td>no</td></tr><tr><td>Read committed</td><td>no</td><td>yes</td><td>yes</td><td>no</td></tr><tr><td>Read uncommitted</td><td>yes</td><td>yes</td><td>yes</td><td>no</td></tr></tbody></table><ul><li>脏读：一个事务处理过程里读取了另一个未提交的事务中的数据</li><li>不可重复读：在一个事务的两次查询中数据不一致</li><li>幻读：幻读是事务非独立执行时发生的一种现象，如事务T1批量对一个表中某一列列值为1的数据修改为2的变更，<br>但是在这时，事务T2对这张表插入了一条列值为1的数据，并完成提交<br>此时，如果事务T1查看刚刚完成操作的数据，发现还有一条列值为1的数据没有进行修改</li></ul><h4 id="默认隔离级别"><a href="#默认隔离级别" class="headerlink" title="默认隔离级别"></a>默认隔离级别</h4><p>Mysql默认隔离级别：Repeatable read<br>sql server默认隔离级别：Read committed</p><h4 id="如何设置隔离级别"><a href="#如何设置隔离级别" class="headerlink" title="如何设置隔离级别"></a>如何设置隔离级别</h4><p>（1）方法一</p><ol><li>使用vi打开mysql配置文件<br>sudo vi /etc/mysql/mysql.conf.d/mysqld.cnf</li><li>在文件的最末尾添加如下配置， 指定mysql数据库的隔离级别为READ-COMMITTED（transaction-isolation=READ-COMMITTED）；可选参数有：READ-UNCOMMITTED, READ-COMMITTED, REPEATABLE-READ, SERIALIZABLE.</li><li>在终端中重启mysql服务<br>sudo service mysql restart</li></ol><p>（2）方法二：</p><ol><li>进入mysql终端</li><li>设置隔离级别，可选的参数READ UNCOMMITTED  | REPEATABLE READ | SERIALIZABLE<br> SET GLOBAL TRANSACTION ISOLATION LEVEL READ COMMITTED;</li></ol>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>qmq消息队列-高可用</title>
      <link href="/2019/06/19/qmq-xiao-xi-dui-lie-gao-ke-yong/"/>
      <url>/2019/06/19/qmq-xiao-xi-dui-lie-gao-ke-yong/</url>
      
        <content type="html"><![CDATA[<p>今天分享下qmq高可用的特性</p><h4 id="高可用说明"><a href="#高可用说明" class="headerlink" title="高可用说明"></a>高可用说明</h4><p>qmq高可用主要从两个角度提供：</p><ul><li>分片：qmq不是基于partition，可以很容易通过添加更多的记起提高一个subject的可用性，消息按照一定的负载均衡策略分布在不同的机器上，某台机器离线后producer将不再将消息发送给该Server</li><li>复制：QMQ通过主从复制来提高单机可用性。QMQ将服务端集群划分为多个group，每个group包含一个master和一个slave。消息的发送和消费全部指向master，slave只为保证可用性</li></ul><h4 id="主从切换"><a href="#主从切换" class="headerlink" title="主从切换"></a>主从切换</h4><ul><li>不支持自动主从切换，需要人工介入；</li><li>切换步骤：<ul><li>将某组设置为readonly，设置readonly之后，该组将不再接受新的消息；</li><li>等待主从完全同步，可以通过观察master的slaveMessageLogLag监控了解；</li><li>停止slave， 停止master；</li><li>执行ReplaceBroker命令切换角色(该步骤一定要在停止应用之后执行)；</li><li>启动slave， 启动master；</li></ul></li></ul><h4 id="部署方案实例"><a href="#部署方案实例" class="headerlink" title="部署方案实例"></a>部署方案实例</h4><ul><li>metaserver：部署两台应用，然后配置nginx作为负载均衡，确保mysql可用；</li><li>broker：部署两组，每组为一主一从两台，则至少部署4台；</li><li>delay server：同broker部署方式(如没有延时消息可以不部署)；</li><li>watchdog：建议部署两台，但某个时刻只有一台工作，当一台故障会自动切换(如无事务或持久化消息可以不部署)；</li></ul>]]></content>
      
      
      <categories>
          
          <category> qmq </category>
          
      </categories>
      
      
        <tags>
            
            <tag> qmq </tag>
            
            <tag> 消息队列 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>elasticsearch学习系列-乐观并发控制</title>
      <link href="/2019/06/18/elasticsearch-xue-xi-xi-lie-le-guan-bing-fa-kong-zhi/"/>
      <url>/2019/06/18/elasticsearch-xue-xi-xi-lie-le-guan-bing-fa-kong-zhi/</url>
      
        <content type="html"><![CDATA[<p>今天介绍下elasticsearch中的乐观并发控制机制</p><h3 id="并发控制"><a href="#并发控制" class="headerlink" title="并发控制"></a>并发控制</h3><ul><li>并发控制分为悲观的和乐观的，对应有我们的乐观锁和悲观锁。</li><li>悲观锁假设冲突随时发生，在处理前必须获得排他的锁再处理</li><li>乐观锁则认为不存在冲突，先处理，若最后发现在处理过程中发生了改变，则取消改变，回滚处理；</li></ul><h3 id="es的乐观并发控制"><a href="#es的乐观并发控制" class="headerlink" title="es的乐观并发控制"></a>es的乐观并发控制</h3><ul><li>Elasticsearch是异步和并发的，这意味着这些复制请求被并行发送，并且到达目的地时也许 顺序是乱的 。 Elasticsearch 需要一种方法确保文档的旧版本不会覆盖新的版本</li><li>我们可以利用 version 号来确保 应用中相互冲突的变更不会导致数据丢失。我们通过指定想要修改文档的 version 号来达到这个目的。 如果该版本不是当前版本号，我们的请求将会失败</li><li>我们可以是使用其它数据库作为主要的数据存储，使用 Elasticsearch 做数据检索， 这意味着主数据库的所有更改发生时都需要被复制到 Elasticsearch ，如果多个进程负责这一数据同步，你可能遇到类似于之前描述的并发问题<ul><li>如果你的主数据库已经有了版本号 — 或一个能作为版本号的字段值比如 timestamp — 那么你就可以在 Elasticsearch 中通过增加 version_type=external 到查询字符串的方式重用这些相同的版本号， 版本号必须是大于零的整数， 且小于 9.2E+18 — 一个 Java 中 long 类型的正值</li><li>外部版本号的处理方式和我们之前讨论的内部版本号的处理方式有些不同， Elasticsearch 不是检查当前 version 和请求中指定的版本号是否相同， 而是检查当前 version 是否 小于 指定的版本号。 如果请求成功，外部的版本号作为文档的新 version 进行存储</li><li>外部版本号不仅在索引和删除请求是可以指定，而且在 创建 新文档时也可以指定</li></ul></li></ul><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ul><li>乐观控制在性能上通常更有优势，尤其是在读大部分都是读操作的场景</li><li>如果实际上确实存在很多冲突，乐观锁机制通常会退化，性能甚至低于悲观并发机制</li></ul>]]></content>
      
      
      <categories>
          
          <category> elasticsearch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> elasticsearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分布式系统理论介绍</title>
      <link href="/2019/06/13/fen-bu-shi-xi-tong-li-lun-jie-shao/"/>
      <url>/2019/06/13/fen-bu-shi-xi-tong-li-lun-jie-shao/</url>
      
        <content type="html"><![CDATA[<p>本文介绍关于分布式系统的一些理论，后续还会涉及到</p><h3 id="CAP理论"><a href="#CAP理论" class="headerlink" title="CAP理论"></a>CAP理论</h3><ul><li>一致性（C）：在分布式系统中的所有数据备份，在同一时刻是否有同样的值。（等同于所有节点访问同一份最新的数据副本</li><li>可用性（A）：在集群中一部分节点故障后，集群整体是否还能响应客户端的读写请求。（对数据更新具备高可用性）</li><li>分区容忍性（P）：以实际效果而言，分区相当于对通信的时限要求。系统如果不能在一定时限内达成数据一致性，就意味着发生了分区的情况，必须就当前操作在C和A之间做出选择</li><li>三者很难同时满足，一般根据系统处理业务场景在某一点上进行折中</li></ul><h3 id="BASE理论"><a href="#BASE理论" class="headerlink" title="BASE理论"></a>BASE理论</h3><ul><li>Basically Available, Soft state, Eventually consistent（基本可用、软状态、最终一致性）</li></ul><h3 id="Paxos"><a href="#Paxos" class="headerlink" title="Paxos"></a>Paxos</h3><ul><li>是一个解决分布式系统中，多个节点之间就某个值（提案）达成一致（决议）的通信协议</li><li>两阶段协议，分为Prepare阶段和Accept阶段<ul><li>Prepare阶段<ul><li>Proposer生成全局唯一且递增的提案ID（生成方法很多，比如时间戳+IP+序列号等），向Paxos集群的所有机器发送请求，这里无须携带提案内容，只携带提案ID即可（且把提案id叫作Pn，也有一种说法ID其实代表版本version）</li><li>Acceptor收到提案请求后，做出以下约定：1）不再应答&lt;=Pn的Prepare请求 2）对于&lt;Pn的Accept请求亦不处</li></ul></li><li>Accept阶段<ul><li>Proposer收集到多数派应答（这里的多数派，就是超过n/2+1, n是集群数）Prepare阶段的返回值后，从中选择proposalID最大的提案内容，作为要发起Accept的提案，如果这个提案为空值，则可以自己随意决定提案内容。然后携带上当前proposalID，向Paxos集群的所有机器发送Accpet请求</li><li>Accpetor收到Accpet请求后，检查不违背自己之前做出约定的情况下，持久化当前Proposal ID和提案内容。最后Proposer收集到多数派应答的Accept回复后，形成决议</li></ul></li></ul></li></ul><h3 id="2PC"><a href="#2PC" class="headerlink" title="2PC"></a>2PC</h3><ul><li>在事务处理、关系型数据库及计算机网络中，2阶段提交协议（2PC）是一种典型的原子提交协议（atomic commitment protocol）。它是一种由协调器来处理分布式原子参与者是提交或者回滚事务的分布式算法</li><li>协议包括2个阶段<ul><li>提交请求阶段或者叫投票阶段：该阶段的任务是确定相关参与者对于事务处理是否准备就绪，YES代表可以commit, NO则反之</li><li>提交阶段：基于投票结果，由协调器决定提交事务抑或是退出事务处理；各事务参与者遵循指示，对本地事务资源做需要的动作</li></ul></li><li>最大的不足是提交协议是阻塞型协议，如果事务协调器宕机，某些参与者将无法解决他们的事务：一个参与者发送确认消息给协调器，因协调器无法工作而导致事务未处理完而处于悬挂状态</li></ul><h3 id="3PC"><a href="#3PC" class="headerlink" title="3PC"></a>3PC</h3><ul><li>第一阶段，投票，事务协调器询问参与者是否能提交（canCommit），都得到肯定回答后，继续第二阶段。第二阶段是预提交，都确认预提交成功后，进行第三阶段。第三阶段就是真实的提交，成功则完成事务；失败则继续重试</li><li>3PC是在2PC的基础上增加了一次交互，也就是preCommit（又称预提交）。只要预提交都成功，则一定要保证doCommit提交成功，即使协调器在下一阶段不可用，或者调用超时</li></ul><h3 id="Raft"><a href="#Raft" class="headerlink" title="Raft"></a>Raft</h3><ul><li>Paxos和Raft都是为了实现一致性（Consensus）这个目标，这个过程如同选举一样，参选者需要说服大多数选民（服务器）投票给他，一旦选定后就跟随其操作。Paxos和Raft的区别在于选举的具体过程不同</li><li>选举过程：<ul><li>任何一个服务器都可以成为一个候选者，它向其他服务器（选民）发出要求选举自己的请求</li><li>其他服务器同意了，回复OK（同意）指令</li><li>这样，这个候选者就成为领导者，它可以向选民们发出要执行具体操作动作的指令，比如进行日志复制</li><li>如果一旦这个Leader宕机崩溃了，那么Follower中会有一个成为候选者，发出邀票选举，相当于再次执行1）～2）的步骤</li></ul></li></ul><h3 id="解决脑裂问题"><a href="#解决脑裂问题" class="headerlink" title="解决脑裂问题"></a>解决脑裂问题</h3><ul><li>指在一个高可用（HA）系统中，当联系着的两个节点断开联系时，本来为一个整体的系统，分裂为两个独立节点，这时两个节点开始争抢共享资源，结果会导致系统混乱，数据损坏</li><li>通过心跳检测做主备切换的时候，就存在不确定性。心跳检测的不确定性是发生脑裂问题的一个非常重要的原因。比如Slave提供服务了，但此前被判死的Master又“复活”了，还在继续工作，则对应用程序逻辑带来未知因素，其中就包括抢夺资源</li><li>有一种做法称为设置仲裁机制，例如设置第三方检测服务器（Monitor），当Slave确定准备接管Master时，让Monitor也ping一下Master，如果没有通讯，则判断其“死亡”；同时Master在对外提供服务时，每隔一段时间比如10s由Master服务器ping Slave服务器和Monitor，如果均出现异常，则暂定业务操作，重试。重试多次之后则退出程序执行或者执行服务器重启操作</li><li>通过Lease机制也可以进一步处理双主脑裂问题。我们假设Slave已经在提供服务了，对应的Server服务器则获得Slave颁发的Lease。假设老Master仍在提供服务，则Lease必然是过期的，因此请求失效，老Master请求频繁时效的情况下，可以通过配置监控点触发报警，以人工介入让老Master放弃身份，转换为Slave</li></ul><h3 id="MVCC"><a href="#MVCC" class="headerlink" title="MVCC"></a>MVCC</h3><ul><li>基于多版本并发控制，乐观机制</li></ul>]]></content>
      
      
      <categories>
          
          <category> 分布式系统 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分布式系统 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Elasticsearch学习系列-入门介绍</title>
      <link href="/2019/03/29/elasticsearch-xue-xi-xi-lie-ru-men-jie-shao/"/>
      <url>/2019/03/29/elasticsearch-xue-xi-xi-lie-ru-men-jie-shao/</url>
      
        <content type="html"><![CDATA[<p>elasticsearch是功能强大的基于Lucene实现的开源搜索引擎。<br>本文主要从以下个方面对其进行入门介绍。<br><a href="https://es.xiaoleilu.com/010_Intro/05_What_is_it.html" target="_blank" rel="noopener">推荐文档</a></p><h4 id="使用场景和优势"><a href="#使用场景和优势" class="headerlink" title="使用场景和优势"></a>使用场景和优势</h4><ul><li>当我们的数据量非常大的时候，我们会考虑进行分库分表，但是分库分表需要考虑依赖拆分的字段，在某些场景下会很复杂。这时候es的优势可以体现出来：<br>支持PB级数据的高效存取；</li><li>当我们的业务数据结构很复杂，表之间的关联关系在关系型数据库中表达困难，表之间的关联错综复杂，我们可以考虑es：他可以以json形式存储结构化和非结构化的数据；</li><li>此外他还是实时文件存储，支持实时分析搜索；</li></ul><h4 id="如何使用"><a href="#如何使用" class="headerlink" title="如何使用"></a>如何使用</h4><ul><li>elasticsearch的使用非常简单。在本地可以很轻松的搭建起来。下面列出简单的步骤（如windows本地）<ul><li><a href="https://www.elastic.co/cn/downloads/elasticsearch" target="_blank" rel="noopener">下载地址</a>下载对应的包，如windows下的biz包</li><li>下载后解压出来，点击es/bin/下的elasticsearch.bat（linux下执行bin/elasticsearch，可<a href="https://juejin.im/post/58d1d7530ce4630057e6053a#heading-2" target="_blank" rel="noopener">参考</a>）</li><li>打开本地：<a href="http://localhost:9200/">http://localhost:9200/</a> 看到正确的json，即安装运行成功</li></ul></li><li>向es内存取数据（具体的字段说明下一节说明）<ul><li><img src="/images/post.png" alt="post保存数据"></li><li><img src="/images/get.png" alt="get查询数据"></li></ul></li></ul><h4 id="基本概念说明"><a href="#基本概念说明" class="headerlink" title="基本概念说明"></a>基本概念说明</h4><ul><li>elasticsearch提供了非常好用的restful api操作数据，如上节我们看到的get post，还有put delete等简单操作；</li><li>这里需要对elasticsearch的一些基本概念介绍下：<ul><li>index：索引，是elasticsearch存储数据的逻辑区域，类似关系型数据库中的database；</li><li>document：文档，elasticsearch用json标示一个对象，类似关系型数据库中的一行数据；</li><li>type：类型，文档归属一种type，类似关系型数据库中的table；</li><li>field：字段，类似关系型数据库中的字段；</li></ul></li><li>在es中可以按照以上概念对数据进行组织，存储，查询，聚合等操作；</li></ul><h4 id="更多特性和优势"><a href="#更多特性和优势" class="headerlink" title="更多特性和优势"></a>更多特性和优势</h4><ul><li>DSL查询： elasticsearch提供了功能十分强大的DSL查询，用于复杂的场景，可以看文档了解这块，基本上可以满足业务的各种要求；</li><li>分布式集群：非常便于扩展，支持大量级的数据存储查询；</li><li>还有排序，搜索…等更多更复杂的特性我们会在后续的使用以及专题中进行更详细的介绍。</li></ul>]]></content>
      
      
      <categories>
          
          <category> elasticsearch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> elasticsearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>elasticsearch学习系列-搜索浅尝</title>
      <link href="/2019/02/15/elasticsearch-xue-xi-xi-lie-sou-suo-qian-chang/"/>
      <url>/2019/02/15/elasticsearch-xue-xi-xi-lie-sou-suo-qian-chang/</url>
      
        <content type="html"><![CDATA[<p>本文简单介绍ES搜索的一些简单尝试</p><h4 id="检索文档"><a href="#检索文档" class="headerlink" title="检索文档"></a>检索文档</h4><pre><code>GET /_index/_type/_id</code></pre><p>根据库、类型、id搜索数据</p><h4 id="简单搜索"><a href="#简单搜索" class="headerlink" title="简单搜索"></a>简单搜索</h4><pre><code>GET /_index/_type/_search</code></pre><p>搜索索引_index内类型_type内的所有数据，默认返回10条</p><h4 id="查询表达式搜索"><a href="#查询表达式搜索" class="headerlink" title="查询表达式搜索"></a>查询表达式搜索</h4><pre><code>GET /_index/_type/_search{    &quot;query&quot; : {        &quot;match&quot; : {            &quot;name&quot; : &quot;Smith&quot;        }    }}</code></pre><p>搜索name=Smith的数据</p><h4 id="复杂搜索"><a href="#复杂搜索" class="headerlink" title="复杂搜索"></a>复杂搜索</h4><pre><code>GET /_index/_type/_search{    &quot;query&quot; : {        &quot;bool&quot;: {            &quot;must&quot;: {                &quot;match&quot; : {                    &quot;name&quot; : &quot;smith&quot;                }            },            &quot;filter&quot;: {                &quot;range&quot; : {                    &quot;age&quot; : { &quot;gt&quot; : 30 }                }            }        }    }}</code></pre><p>查找name=Smith，age大于30的数据</p><h4 id="全文搜索"><a href="#全文搜索" class="headerlink" title="全文搜索"></a>全文搜索</h4><pre><code>GET /_index/_type/_search{    &quot;query&quot; : {        &quot;match&quot; : {            &quot;about&quot; : &quot;abc def&quot;        }    }}</code></pre><p>搜索数据包含 abc def，或abd 、 def的数据</p><h4 id="短语搜索"><a href="#短语搜索" class="headerlink" title="短语搜索"></a>短语搜索</h4><pre><code>GET /_index/_type/_search{    &quot;query&quot; : {        &quot;match_phrase&quot; : {            &quot;about&quot; : &quot;abc def&quot;        }    }}</code></pre><p>搜索数据包含 abc def的数据，不可拆分</p>]]></content>
      
      
      <categories>
          
          <category> elasticsearch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> elasticsearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分布式系统下的一些概念介绍</title>
      <link href="/2019/02/13/fen-bu-shi-xi-tong-xia-de-yi-xie-gai-nian-jie-shao/"/>
      <url>/2019/02/13/fen-bu-shi-xi-tong-xia-de-yi-xie-gai-nian-jie-shao/</url>
      
        <content type="html"><![CDATA[<h3 id="进程与线程"><a href="#进程与线程" class="headerlink" title="进程与线程"></a>进程与线程</h3><ul><li>进程是具有一定独立功能的程序关于某个数据集合上的一次运行活动，进程是系统进行资源分配和调度的一个独立单位。线程是进程的一个实体，是CPU调度和分派的基本单位，它是比进程更小的能独立运行的基本单位。</li><li>线程自己基本上不拥有系统资源，只拥有一点在运行中必不可少的资源（如程序计数器、一组寄存器和栈），但是它可与同属一个进程的其他的线程共享进程所拥有的全部资源</li></ul><h3 id="并发"><a href="#并发" class="headerlink" title="并发"></a>并发</h3><ul><li>当有多个线程在操作时，如果系统只有一个CPU，则它根本不可能真正同时进行一个以上的线程，它只能把CPU运行时间划分成若干个时间段，再将时间段分配给各个线程执行，在一个时间段的线程代码运行时，其他线程处于挂起状态。这种方式我们称之为并发</li></ul><h3 id="锁"><a href="#锁" class="headerlink" title="锁"></a>锁</h3><ul><li>锁（lock）作为用于保护临界区（critical section）的一种机制，被广泛应用在多线程程序中，比如Java（synchronized , ReentrantLock…）</li><li>减少或规避锁竞争的一些策略：<ul><li>分拆锁</li><li>分离锁</li><li>避免共享变量缓存</li><li>使用并发容器如Amino</li><li>使用Immutable数据和ThreadLocal中的数据</li></ul></li></ul><h3 id="并行"><a href="#并行" class="headerlink" title="并行"></a>并行</h3><ul><li>当系统有一个以上的CPU时，则线程的操作有可能非并发。当一个CPU执行一个线程时，另一个CPU可以执行另一个线程，两个线程互不抢占CPU资源，可以同时进行，这种方式我们称之为并行（Parallel）</li><li>和并发的区别：并发和并行是即相似又有区别的两个概念，并行是指两个或者多个事件在同一时刻发生；而并发是指两个或多个事件在同一时间间隔内发生</li></ul><h3 id="集群"><a href="#集群" class="headerlink" title="集群"></a>集群</h3><ul><li>集群是一组相互独立的、通过高速网络互联的计算机，它们构成了一个组，并以单一系统的模式加以管理</li><li>集群配置是用于提高可用性和可伸缩性。其实，分布式系统可以表达为很多机器组成的集群，靠彼此之间的网络通信，担当的角色可能不同，共同完成同一件事情的系统</li></ul><h3 id="状态特性"><a href="#状态特性" class="headerlink" title="状态特性"></a>状态特性</h3><ul><li>在大部分应用中都提倡服务无状态，分布式环境中的任何节点（Node）也是无状态的</li><li>无状态是指不保存存储状态，则可以随意重启和替代，便于做扩展。比如负载均衡服务器Nginx是无状态的，应用服务绝大部分也是无状态的，在高压力访问下，撑不住了就加一些机器，扩展很容易</li></ul><h3 id="系统重发和幂等性"><a href="#系统重发和幂等性" class="headerlink" title="系统重发和幂等性"></a>系统重发和幂等性</h3><ul><li>网络重复请求，造成的原因有多种</li><li>幂等性就是调用1次和调用N次要返回一样的结果</li></ul>]]></content>
      
      
      <categories>
          
          <category> 分布式系统 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分布式系统 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据库关于分库分表的整理</title>
      <link href="/2019/01/30/shu-ju-ku-guan-yu-fen-ku-fen-biao-de-zheng-li/"/>
      <url>/2019/01/30/shu-ju-ku-guan-yu-fen-ku-fen-biao-de-zheng-li/</url>
      
        <content type="html"><![CDATA[<p>今天分享一些项目中关于数据库分库分表的经验</p><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><ul><li>一般随着业务的增长，出现以下问题都需要考虑分库分表<ul><li>单表的字段过多，</li><li>数据量过大，</li><li>db请求压力过大</li></ul></li></ul><h3 id="操作"><a href="#操作" class="headerlink" title="操作"></a>操作</h3><ul><li>如果表的字段过多，可以考虑垂直分，将表的一些字段拆分出去建立扩展表</li><li>数据量过大的时候，可以考虑数据的当前总量和增量，进行水平拆分</li><li>数据库请求压力大的时候，可以进行分区，进行分库管理</li></ul><h3 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h3><ul><li>拆分表的字段以及分表策略需要根据实际情况而定，分表后如果需要根据非分表字段查询是一件很痛苦的事情</li><li>基于上面提到的问题，我们可以考虑在分表的同时使用es等存储数据方便进行索引</li></ul>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>相对论中的时空</title>
      <link href="/2019/01/22/xiang-dui-lun-zhong-de-shi-kong/"/>
      <url>/2019/01/22/xiang-dui-lun-zhong-de-shi-kong/</url>
      
        <content type="html"><![CDATA[<p>  相信很多人跟我一样，很早就接触过时空这个词，但是却从没有深究过它。<br>  本文将基于自己最近的阅读简单和大家聊一聊时空这个概念，希望能激发大家对此类科学的兴趣，也希望有高人对此能指点一二。<br>  在讲它之前，我想简单先聊几个概念。  </p><h4 id="狭义相对论"><a href="#狭义相对论" class="headerlink" title="狭义相对论"></a>狭义相对论</h4><p>  爱因斯坦的相对论相信绝大数朋友都听过。当然这一段也不是我们此处的核心。我这里只是简单介绍一下以方便后面对时空的描述。<br>  狭义相对论是基于两个假设前提：</p><ul><li>光速在任何参考系内不变</li><li><p>在任何惯性系内物理规律保持不变</p><p>然后基于牛顿的物理定律和公司，加入这两个假设前提，爱因斯坦推导出狭义相对论的结论：</p></li></ul><ol><li>时间膨胀</li><li>空间收缩（如长度变短）</li><li>速度收缩</li><li>物体运动速度越大，质量越大</li><li>物质的能量m乘c平方</li></ol><h4 id="广义相对论"><a href="#广义相对论" class="headerlink" title="广义相对论"></a>广义相对论</h4><p>  狭义相对论有他的局限性，10年后的广义相对论，爱因斯坦对狭义相对论进行扩展，将理论扩展到非惯性系，根据假设<strong>引力场和加速度是等效的（等效原理），</strong>  得到广义相对论的引力场方程。<br>  广义相对论的核心思想：<strong>物质可以引起时空弯曲，然后物体在弯曲的时空内运动。</strong></p><h4 id="时空"><a href="#时空" class="headerlink" title="时空"></a>时空</h4><p>  简单介绍了相对论（感兴趣的推荐阅读《时间的形状》，后续我也会基于相对论进行思考和分享，欢迎一起讨论），我们引出这个时空概念。通俗的说，时空是时间和空间的结合，是不可分割的一体。爱因斯坦说：<strong>任何物体的运动速度都是光速c-在时空中</strong> 。<em>（以下是我一些发散的思考，用列表的形式记录方便阅读）</em>：</p><ul><li>简单的说就是物体的速度可以分解到三维空间和时间维度，你的速度越快，你的时间维度就过得越慢。所以对光子来说是没有时间概念的。</li><li>太神奇了！我们一直生活在三维的空间世界太久，但是现在，我们来到了四维的时空世界。只是因为我们在空间的速度相对光速而言太慢太慢，我们在时间维度造成的改变太微小。</li><li>时空的概念打开了四维世界的大门，让我们对时间旅行有了新的期待。</li><li>空间不可触摸，但是在我们的认知中他不像时间那样的神秘，但是现在我们并不将他们分开讨论。存在空间的地方自然需要考虑时间。我不禁想到，光在宇宙中的遨游那是怎样的一种体验，他感受不到时间，只是在快速的穿越空间，或者应该说，他并不能体会到两者的区别，他就像我们坐在高铁上在两地间飞驰，时间只是另外一个坐标轴，我们无法想象凌驾时间之上的旅程。</li><li>时空是凹凸不平的，在时空中的运动也受这种弯曲影响，质量越大造成的时空弯曲效应越大；根据相对论速度越快质量越大，光的质量应该无限大，但是光子又是认为没有质量的…</li><li>通过描述4维的时空物体的运动可以得到一个”超光锥””，理论认为事件存在影响的未来光锥和过去光锥，对光锥之外的时空无法造成影响，当然量子不在这个讨论的范畴（量子力学的学习和分享后续也会进行，欢迎一起讨论）；</li><li>我们说的时空更多的是描述三维空间+时间轴，但现代物理认为宇宙之中至少存在10维， 9维空间，加时间维度；有6维空间在基本梨子维度，目前的宏观宇宙暂时是无法进行观测描述的… 那么是不是这个时空在将来会进一步颠覆？</li><li>虽然理论说物体的速度不能超过光速，但是我相信这一点也一定会在未来推翻（粒子的信息传递超光速）。那如果我们的速度超过了光速，我们的运动在这个时空将如何描述？ 时间倒流（若时空弯曲形成莫比乌斯环，当前理论上是可以穿越回到回去的，当然也需要借助虫洞）？ 时间的坐标轴是否也有方向就像长度坐标轴上的正负？希望有天这些疑问可以得到解答。</li></ul><p>本文更多的是简单的介绍，欢迎一起讨论交流~</p>]]></content>
      
      
      <categories>
          
          <category> 科学科幻 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 科学科幻 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>我的博客说明</title>
      <link href="/2018/12/28/wo-de-bo-ke-shuo-ming/"/>
      <url>/2018/12/28/wo-de-bo-ke-shuo-ming/</url>
      
        <content type="html"><![CDATA[<p>   做一件事，要学会倾尽全力</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>redis学习-复制功能</title>
      <link href="/2018/12/11/redis-xue-xi-fu-zhi-gong-neng/"/>
      <url>/2018/12/11/redis-xue-xi-fu-zhi-gong-neng/</url>
      
        <content type="html"><![CDATA[<p>今天介绍下redis的复制功能</p><h3 id="复制配置"><a href="#复制配置" class="headerlink" title="复制配置"></a>复制配置</h3><ul><li>参与复制的Redis实例划分为主节点(master)和从节点(slave)</li><li>复制的数据流是单向的，只能由主节点复制到从节 点。配置复制的方式有以下三种<ul><li>在配置文件中加入slaveof{masterHost}{masterPort}随Redis启动生 效</li><li>在redis-server启动命令后加入–slaveof{masterHost}{masterPort}生 效</li><li>直接使用命令:slaveof{masterHost}{masterPort}生效</li></ul></li></ul><h3 id="拓扑介绍"><a href="#拓扑介绍" class="headerlink" title="拓扑介绍"></a>拓扑介绍</h3><ul><li>一主一从结构<ul><li>最简单的复制拓扑结构，用于主节点出现宕机时从节点 提供故障转移支持</li><li>当应用写命令并发量较高且需要持久 化时，可以只在从节点上开启AOF，这样既保证数据安全性同时也避免了持 久化对主节点的性能干扰</li><li>当主节点关闭持久化功能时， 如果主节点脱机要避免自动重启操作。因为主节点之前没有开启持久化功能 自动重启后数据集为空，这时从节点如果继续复制主节点会导致从节点数据 也被清空的情况，丧失了持久化的意义。安全的做法是在从节点上执行 slaveof no one断开与主节点的复制关系，再重启主节点从而避免这一问题</li></ul></li><li>一主多从结构<ul><li>一主多从结构(又称为星形拓扑结构)使得应用端可以利用多个从节点 实现读写分离</li><li>对于读占比较大的场景，可以把读命令发送到 从节点来分担主节点压力。同时在日常开发中如果需要执行一些比较耗时的 读命令，如:keys、sort等，可以在其中一台从节点上执行，防止慢查询对 主节点造成阻塞从而影响线上服务的稳定性</li></ul></li><li>树状主从结构<ul><li>树状主从结构(又称为树状拓扑结构)使得从节点不但可以复制主节点 数据，同时可以作为其他从节点的主节点继续向下层复制</li><li>通过引入复制中 间层，可以有效降低主节点负载和需要传送给从节点的数据量</li></ul></li></ul><h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h3><ul><li>复制过程<ul><li>保存主节点(master)信息：</li><li>从节点(slave)内部通过每秒运行的定时任务维护复制相关逻辑， 当定时任务发现存在新的主节点后，会尝试与该节点建立网络连接</li><li>发送ping命令</li><li>权限验证。如果主节点设置了requirepass参数，则需要密码验证， 从节点必须配置masterauth参数保证与主节点相同的密码才能通过验证;如 果验证失败复制将终止，从节点重新发起复制流程</li><li>同步数据集。（主从复制连接正常通信后，对于首次建立复制的场 景，主节点会把持有的数据全部发送给从节点，这部分操作是耗时最长的步 骤。Redis在2.8版本以后采用新复制命令psync进行数据同步，原来的sync命 令依然支持，保证新旧版本的兼容性。新版同步划分两种情况:全量同步和 部分同步）</li><li>命令持续复制。当主节点把当前的数据同步给从节点后，便完成了 复制的建立流程。接下来主节点会持续地把写命令发送给从节点，保证主从 数据一致性</li></ul></li><li>数据同步<ul><li>全量复制:一般用于初次复制场景，Redis早期支持的复制功能只有全 量复制，它会把主节点全部数据一次性发送给从节点，当数据量较大时，会 对主从节点和网络造成很大的开销</li><li>部分复制:用于处理在主从复制中因网络闪断等原因造成的数据丢失 场景，当从节点再次连上主节点后，如果条件允许，主节点会补发丢失数据 给从节点。因为补发的数据远远小于全量数据，可以有效避免全量复制的过 高开销</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>redis学习-支持的数据结构</title>
      <link href="/2018/10/30/redis-xue-xi-zhi-chi-de-shu-ju-jie-gou/"/>
      <url>/2018/10/30/redis-xue-xi-zhi-chi-de-shu-ju-jie-gou/</url>
      
        <content type="html"><![CDATA[<p>今天分享下redis支持的一些数据结构</p><h3 id="字符串"><a href="#字符串" class="headerlink" title="字符串"></a>字符串</h3><ul><li>字符串类型是Redis最基础的数据结构。首先键都是字符串类型，而且 其他几种数据结构都是在字符串类型基础上构建的，所以字符串类型能为其 他数据结构的学习奠定基础</li><li>字符串类型的值实际可以 是字符串(简单的字符串、复杂的字符串(例如JSON、XML))、数字 (整数、浮点数)，甚至是二进制(图片、音频、视频)，但是值最大不能 超过512MB</li><li>setnx和setxx可以作为分布式锁的一种 实现方案</li><li>可以使用mget这样的批量命令</li><li>字符串类型的内部编码有3种（根据当前值的类型和长度决定使用哪种内部编码实现）：<ul><li>int:8个字节的长整型</li><li>embstr:小于等于39个字节的字符串<br>-raw:大于39个字节的字符串</li></ul></li></ul><h3 id="哈希"><a href="#哈希" class="headerlink" title="哈希"></a>哈希</h3><ul><li>键值本身又是一个键值对结构</li><li>在使用hgetall时，如果哈希元素个数比较多，会存在阻塞Redis的可能。 如果开发人员只需要获取部分field，可以使用hmget，如果一定要获取全部 field-value，可以使用hscan命令，该命令会渐进式遍历哈希类型</li><li>内部编码：<ul><li>ziplist(压缩列表):当哈希类型元素个数小于hash-max-ziplist-entries 配置(默认512个)、同时所有值都小于hash-max-ziplist-value配置(默认64 字节)时，Redis会使用ziplist作为哈希的内部实现，ziplist使用更加紧凑的 结构实现多个元素的连续存储，所以在节省内存方面比hashtable更加优秀</li><li>hashtable(哈希表):当哈希类型无法满足ziplist的条件时，Redis会使 用hashtable作为哈希的内部实现，因为此时ziplist的读写效率会下降，而 hashtable的读写时间复杂度为O(1)</li></ul></li></ul><h3 id="列表"><a href="#列表" class="headerlink" title="列表"></a>列表</h3><ul><li>用来存储多个有序的字符串</li><li>列表类型有两个特点:第一、列表中的元素是有序的，这就意味着可以 通过索引下标获取某个元素或者某个范围内的元素列表，第二、列表中的元素可以是重复的。</li><li>内部编码：<ul><li>ziplist(压缩列表):当列表的元素个数小于list-max-ziplist-entries配置 (默认512个)，同时列表中每个元素的值都小于list-max-ziplist-value配置时 (默认64字节)，Redis会选用ziplist来作为列表的内部实现来减少内存的使 用</li><li>linkedlist(链表):当列表类型无法满足ziplist的条件时，Redis会使用 linkedlist作为列表的内部实现</li></ul></li><li>列表的使用场景很多，如<ul><li>lpush+lpop=Stack(栈)</li><li>lpush+rpop=Queue(队列)</li><li>lpsh+ltrim=Capped Collection(有限集合)</li><li>lpush+brpop=Message Queue(消息队列)</li></ul></li></ul><h3 id="集合"><a href="#集合" class="headerlink" title="集合"></a>集合</h3><ul><li>是用来保存多个的字符串元素，和列表类型不一 样的是，集合中不允许有重复元素，并且集合中的元素是无序的，不能通过索引下标获取元素</li><li>内部编码：<ul><li>intset(整数集合):当集合中的元素都是整数且元素个数小于set-max- intset-entries配置(默认512个)时，Redis会选用intset来作为集合的内部实 现，从而减少内存的使用</li><li>hashtable(哈希表):当集合类型无法满足intset的条件时，Redis会使 用hashtable作为集合的内部实现</li></ul></li><li>使用场景推荐：<ul><li>sadd=Tagging(标签)</li><li>spop/srandmember=Random item(生成随机数，比如抽奖)</li><li>sadd+sinter=Social Graph(社交需求)</li></ul></li></ul><h3 id="有序集合"><a href="#有序集合" class="headerlink" title="有序集合"></a>有序集合</h3><ul><li>保留了集合不能有重复成员的特性，有序集合中的元素可以排序，给每个元素设置一个分数(score)作为排序的依 据</li><li>内部编码：<ul><li>ziplist(压缩列表):当有序集合的元素个数小于zset-max-ziplist- entries配置(默认128个)，同时每个元素的值都小于zset-max-ziplist-value配 置(默认64字节)时，Redis会用ziplist来作为有序集合的内部实现，ziplist 可以有效减少内存的使用</li><li>skiplist(跳跃表):当ziplist条件不满足时，有序集合会使用skiplist作 为内部实现，因为此时ziplist的读写效率会下降</li></ul></li><li>有序集合比较典型的使用场景就是排行榜系统</li></ul><h3 id="Bitmaps"><a href="#Bitmaps" class="headerlink" title="Bitmaps"></a>Bitmaps</h3><ul><li>Bitmaps本身不是一种数据结构，实际上它就是字符串(如图3-10所 示)，但是它可以对字符串的位进行操作</li><li>Bitmaps单独提供了一套命令，所以在Redis中使用Bitmaps和使用字符 串的方法不太相同。可以把Bitmaps想象成一个以位为单位的数组，数组的 每个单元只能存储0和1，数组的下标在Bitmaps中叫做偏移量</li></ul><h3 id="HyperLogLog"><a href="#HyperLogLog" class="headerlink" title="HyperLogLog"></a>HyperLogLog</h3><ul><li>HyperLogLog并不是一种新的数据结构(实际类型为字符串类型)，而是一种基数算法，通过HyperLogLog可以利用极小的内存空间完成独立总数 的统计，数据集可以是IP、Email、ID等</li></ul><h3 id="特别说明"><a href="#特别说明" class="headerlink" title="特别说明"></a>特别说明</h3><ul><li>可以使用类似setnx和setxx实现分布式锁</li><li>批量操作使用mget之类的批量命令减少网络开销</li><li>redis是单线程模式，类似keys， hgetall类似的命令可能会阻塞redis，生产环境尽量不用</li><li><a href="http://doc.redisfans.com/" target="_blank" rel="noopener">redis命令参考</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>weixin_小程序开发（一）</title>
      <link href="/2018/09/15/weixin-xiao-cheng-xu-kai-fa-yi/"/>
      <url>/2018/09/15/weixin-xiao-cheng-xu-kai-fa-yi/</url>
      
        <content type="html"><![CDATA[<p>TODO</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>java并发专题-线程介绍</title>
      <link href="/2018/09/08/java-bing-fa-zhuan-ti-xian-cheng-jie-shao/"/>
      <url>/2018/09/08/java-bing-fa-zhuan-ti-xian-cheng-jie-shao/</url>
      
        <content type="html"><![CDATA[<p>今天介绍下并发中使用的线程概念</p><h3 id="线程简介"><a href="#线程简介" class="headerlink" title="线程简介"></a>线程简介</h3><ul><li>会创建一个Java进程。现代操作系统调度的最小单元是线程，也叫轻量级进程（Light WeightProcess），在一个进程里可以创建多个线程，这些线程都拥有各自的计数器、堆栈和局部变量等属性，并且能够访问共享的内存变量。处理器在这些线程上高速切换，让使用者感觉到这些线程在同时执行</li><li>多线程的优势：<ul><li>更多的处理器核心，充分利用</li><li>更快的响应时间</li><li>更好的编程模型</li></ul></li><li>线程优先级<ul><li>线程优先级就是决定线程需要多或者少分配一些处理器资源的线程属性</li><li>线程优先级不能作为程序正确性的依赖，因为操作系统可以完全不用理会Java线程对于优先级的设定</li></ul></li><li>线程的状态：<ul><li>NEW: 初始状态，还没调用start()</li><li>RUNNABLE: 运行状态</li><li>BLOCKED： 阻塞状态，阻塞于锁</li><li>WAITING： 等待状态</li><li>TIME_WAITING: 超时等待状态，可在制定时间内自行返回</li><li>TEARMINATED： 终止状态，执行完毕</li></ul></li><li>Daemon线程<ul><li>Daemon线程是一种支持型线程，因为它主要被用作程序中后台调度以及支持性工作。</li><li>当一个Java虚拟机中不存在非Daemon线程的时候，Java虚拟机将会退出。可以通过调用Thread.setDaemon(true)将线程设置为Daemon线程</li></ul></li></ul><h3 id="操作线程（启停）"><a href="#操作线程（启停）" class="headerlink" title="操作线程（启停）"></a>操作线程（启停）</h3><ul><li>线程对象在初始化完成之后，调用start()方法就可以启动这个线程</li><li>中断可以理解为线程的一个标识位属性，它表示一个运行中的线程是否被其他线程进行了中断操作。中断好比其他线程对该线程打了个招呼，其他线程通过调用该线程的interrupt()方法对其进行中断操作</li><li>suspend()、resume()和stop()方法完成了线程的暂停、恢复和终止工作，而且非常“人性化”。（这些API是过期的，不建议使用）</li><li>中断状态是线程的一个标识位，而中断操作是一种简便的线程间交互方式，而这种交互方式最适合用来取消或停止任务。除了中断以外，还可以利用一个boolean变量来控制是否需要停止任务并终止该线程</li></ul><h3 id="线程间通信"><a href="#线程间通信" class="headerlink" title="线程间通信"></a>线程间通信</h3><ul><li>volatile： 关键字volatile可以用来修饰字段（成员变量），就是告知程序任何对该变量的访问均需要从共享内存中获取，而对它的改变必须同步刷新回共享内存，它能保证所有线程对变量访问的可见性</li><li>synchronized：关键字synchronized可以修饰方法或者以同步块的形式来进行使用，它主要确保多个线程在同一个时刻，只能有一个线程处于方法或者同步块中，它保证了线程对变量访问的可见性和排他性</li><li>等待/通知机制：是指一个线程A调用了对象O的wait()方法进入等待状态，而另一个线程B调用了对象O的notify()或者notifyAll()方法，线程A收到通知后从对象O的wait()方法返回，进而执行后续操作</li><li>管道通信：管道输入/输出流和普通的文件输入/输出流或者网络输入/输出流不同之处在于，它主要用于线程之间的数据传输，而传输的媒介为内存，主要包括4种具体实现：PipedOutputStream、PipedInputStream、PipedReader和PipedWriter，前两种面向字节，而后两种面向字符</li><li>Thread.join() : 如果一个线程A执行了thread.join()语句，其含义是：当前线程A等待thread线程终止之后才从thread.join()返回。线程Thread除了提供join()方法之外，还提供了join(long millis)和join(longmillis, int nanos)两个具备超时特性的方法</li><li>ThreadLocal: 线程变量，是一个以ThreadLocal对象为键、任意对象为值的存储结构。这个结构被附带在线程上，也就是说一个线程可以根据一个ThreadLocal对象查询到绑定在这个线程上的一个值,可以通过set(T)方法来设置一个值，在当前线程下再通过get()方法获取到原先设置的值</li></ul><h3 id="线程应用"><a href="#线程应用" class="headerlink" title="线程应用"></a>线程应用</h3><ul><li>数据库链接池</li><li>线程池</li><li>基于线程池的简单web服务器</li></ul>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java </tag>
            
            <tag> 线程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>java-多线程-线程安全简单介绍</title>
      <link href="/2018/07/22/java-duo-xian-cheng-xian-cheng-an-quan-jian-dan-jie-shao/"/>
      <url>/2018/07/22/java-duo-xian-cheng-xian-cheng-an-quan-jian-dan-jie-shao/</url>
      
        <content type="html"><![CDATA[<pre><code>本文对多线程的线程安全做一个简单介绍和探讨。在特定场景下，多线程是一把利刃，可以帮助我们提升业务处理的性能，充分利用服务器的性能，甚至在某些情况下会让编程从逻辑上更简单清晰。但是他同时是一把双刃剑，我们早就习惯了艳丽的玫瑰总是带刺的。很多时候他是复杂的，存在安全风险的。本文将简单谈谈线程安全，也就是多线程下，程序运行正确，运行的和我们的预期是保持一致的。</code></pre><h4 id="原子性"><a href="#原子性" class="headerlink" title="原子性"></a>原子性</h4><pre><code>我们在多线程中常常涉及到这个概念。如果我们的操作不是原子操作，那么在多线程下执行，很容易产生预期之外的结果。如* ++count* 类似这样的操作他就不是一个原子操作，包含了&quot;读 改 写&quot;的操作。</code></pre><h4 id="竞争条件"><a href="#竞争条件" class="headerlink" title="竞争条件"></a>竞争条件</h4><p>我们在程序中常常存在竞争条件，如：</p><ul><li>检查再运行： 我们在检查条件后，执行操作的时候，很可能另外的进场已经修改了此前的条件；如代码中常见的惰性初始化；</li></ul><h4 id="锁"><a href="#锁" class="headerlink" title="锁"></a>锁</h4><p>当我们遇到非原子操作，在多线程下可能会遇到问题。此时我们该怎么做呢？我们考虑使用锁。如java中提供的内置锁机制： synchronized块。</p><ul><li>简单说明下他的运作机制，当某个线程进入此代码块，他将获得锁，此时其他进场将无法获得锁，也就无法执行这段代码块，那么这块可以看做我们上面看到的原子操作，线程们串行地执行这个代码块；</li><li>通过上面的解释你也会意识到，</li></ul>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java </tag>
            
            <tag> 并发 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>java虚拟机垃圾收集算法介绍</title>
      <link href="/2018/05/27/java-xu-ni-ji-la-ji-shou-ji-suan-fa-jie-shao/"/>
      <url>/2018/05/27/java-xu-ni-ji-la-ji-shou-ji-suan-fa-jie-shao/</url>
      
        <content type="html"><![CDATA[<p>今天介绍下java虚拟机内的垃圾收集算法</p><h3 id="分代收集理论"><a href="#分代收集理论" class="headerlink" title="分代收集理论"></a>分代收集理论</h3><ul><li>分代假设：<ul><li>弱分代假说（Weak Generational Hypothesis）：绝大多数对象都是朝生夕灭的</li><li>强分代假说（Strong Generational Hypothesis）：熬过越多次垃圾收集过程的对象就越难以消亡</li></ul></li><li>在Java堆划分出不同的区域之后，垃圾收集器才可以每次只回收其中某一个或者某些部分的区域——因而才有了“Minor GC”“Major GC”“Full GC”这样的回收类型的划分</li></ul><h3 id="标记-清除算法"><a href="#标记-清除算法" class="headerlink" title="标记-清除算法"></a>标记-清除算法</h3><ul><li>算法分为“标记”和“清除”两个阶段：首先标记出所有需要回收的对象，在标记完成后，统一回收掉所有被标记的对象，也可以反过来，标记存活的对象，统一回收所有未被标记的对象</li></ul><h3 id="标记-复制算法"><a href="#标记-复制算法" class="headerlink" title="标记-复制算法"></a>标记-复制算法</h3><ul><li>将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉</li><li>如果内存中多数对象都是存活的，这种算法将会产生大量的内存间复制的开销，但对于多数对象都是可回收的情况，算法需要复制的就是占少数的存活对象，而且每次都是针对整个半区进行内存回收，分配内存时也就不用考虑有空间碎片的复杂情况，只要移动堆顶指针，按顺序分配即可</li><li>缺陷显而易见，空间浪费严重</li><li>Appel式回收的具体做法是把新生代分为一块较大的Eden（通常80%）空间和两块较小的Survivor空间，每次分配内存只使用Eden和其中一块Survivor</li></ul><h3 id="标记-整理算法"><a href="#标记-整理算法" class="headerlink" title="标记-整理算法"></a>标记-整理算法</h3><ul><li>标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向内存空间一端移动，然后直接清理掉边界以外的内存</li></ul>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>git常用命令</title>
      <link href="/2018/05/13/git-chang-yong-ming-ling/"/>
      <url>/2018/05/13/git-chang-yong-ming-ling/</url>
      
        <content type="html"><![CDATA[<p>今天介绍下版本管理工具：git的一些常用命令</p><h3 id="git介绍"><a href="#git介绍" class="headerlink" title="git介绍"></a>git介绍</h3><ul><li>Git是目前世界上最先进的分布式版本控制系统</li><li>可以有效、高速地处理从很小到非常大的项目版本管理</li></ul><h3 id="git原理-参考"><a href="#git原理-参考" class="headerlink" title="git原理(参考 )"></a>git原理(<a href="https://blog.csdn.net/qq360694660/article/details/80256367" target="_blank" rel="noopener">参考</a> )</h3><ul><li>暂存操作会对先每一个文件计算校验和checksum（Git 使用SHA-1 算法计算数据的校验和，通过对文件的内容或目录的结构计算出一个SHA-1 哈希值，作为指纹字符串,该字串由40 个十六进制字符,并将此结果作为数据的唯一标识和索引），然后把当前版本的文件快照保存到本地Git 仓库中（Git 使用blob 类型的对象存储这些文件内容快照），并将校验和加入暂存区域</li><li>使用git commit 新建一个提交对象前，Git 会先计算每一个子目录（项目根目录）的校验和，然后在Git 仓库中将这些目录保存为树（tree）对象。之后Git 创建的提交对象，除了包含相关提交信息以外，还包含着指向这个树对象（项目根目录）的指针，如此它就可以在将来需要的时候，重现此次快照的内容了</li><li>分支：<ul><li>Git 中的分支实际上仅是一个包含所指对象校验和（40 个字符长度SHA-1 字串）的文件，所以创建和销毁一个分支就变得非常廉价。新建一个分支就是向一个文件写入41 个字节（外加一个换行符）</li><li>Git 创建一个新的分支仅仅是创建一个新的分支指针</li><li>有一个名为HEAD 的特别指针，运行git branch 命令，仅仅是建立了一个新的分支，但不会自动切换到这个分支中，所以当前我们仍然在master分支</li><li>git checkout testing，git仅仅是将HEAD指针指向了testing，几乎瞬间完成</li><li>如果这时我们再次修改了文件，并提交(git commit ),仅仅是testing分支指向了最新commit ，而master仍指向在原来的commit</li><li>使用git checkout master切换回master分支。git做了两件事它把HEAD 指针移回到master 分支，并把工作目录中的文件换成了master 分支所指向的快照内容</li><li>在master分支我们修改文件再进行提交，这时项目提交历史产生了分叉</li></ul></li></ul><h3 id="git常用命令介绍"><a href="#git常用命令介绍" class="headerlink" title="git常用命令介绍"></a>git常用命令介绍</h3><ul><li>git init: 初始化</li><li>git add ：对修改保存暂存区</li><li>git commit: 提交改动，生成当前项目的一个快照</li><li>git config user.name “用户名”    git config user.email “Email 地址” 设置用户名和邮件地址</li><li>git branch a： 创建分支a</li><li>git checkout a : 切换到分支a（先保存当前分支的改动）</li><li>git merge a: a分支合并到当前分支</li><li>git log: 查看整个版本历史</li><li>git pull: 获取远程分支的更新（别人的改动）</li><li>git push：自己的改动推到远端（方便别人获取）<br>-</li></ul>]]></content>
      
      
      <categories>
          
          <category> git </category>
          
      </categories>
      
      
        <tags>
            
            <tag> git </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>java-outofmemoryError异常整理</title>
      <link href="/2018/04/23/java-outofmemoryerror-yi-chang-zheng-li/"/>
      <url>/2018/04/23/java-outofmemoryerror-yi-chang-zheng-li/</url>
      
        <content type="html"><![CDATA[<p>今天介绍java中的一些outofmemoryError</p><h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><ul><li><p>java虚拟机栈</p><ul><li>StackOverflowError：如果线程请求的栈深度大于虚拟机所允许的深度</li><li>OutOfMemoryError：当栈扩展时无法申请到足够的内存</li></ul></li><li><p>本地方法栈</p><ul><li>StackOverflowError</li><li>OutOfMemoryError</li></ul></li><li><p>java堆</p><ul><li>OutOfMemoryError</li></ul></li><li><p>方法区</p><ul><li>OutOfMemoryError</li></ul></li><li><p>运动时常量池</p><ul><li>OutOfMemoryError</li></ul></li><li><p>直接内存</p><ul><li>OutOfMemoryError</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>redis学习-基本介绍</title>
      <link href="/2017/05/30/redis-xue-xi-ji-ben-jie-shao/"/>
      <url>/2017/05/30/redis-xue-xi-ji-ben-jie-shao/</url>
      
        <content type="html"><![CDATA[<p>redis是使用简单、性能强大的非关系型数据库。<br>下面简单介绍他的几个特性。<br>后续会进行关于redis支持的数据结构、redis使用场景案例等的分享。</p><h3 id="单线程"><a href="#单线程" class="headerlink" title="单线程"></a>单线程</h3><ul><li>redis的一大特色，使得Redis服务端处理模型变得简单，而且也使得客户端开发变得简单</li></ul><h3 id="速度快"><a href="#速度快" class="headerlink" title="速度快"></a>速度快</h3><ul><li>Redis执行命令的速度非常快，官方给出的数字是读写性 能可以达到10万/秒</li><li>Redis的所有数据都是存放在内存中的</li><li>Redis是用C语言实现的，一般来说C语言实现的程序“距离”操作系统更 近，执行速度相对会更快</li><li>Redis使用了单线程架构，预防了多线程可能产生的竞争问题</li></ul><h3 id="丰富的功能"><a href="#丰富的功能" class="headerlink" title="丰富的功能"></a>丰富的功能</h3><ul><li>提供5种数据结构</li><li>提供了键过期功能，可以用来实现缓存</li><li>提供了发布订阅功能，可以用来实现消息系统</li><li>支持Lua脚本功能，可以利用Lua创造出新的Redis命令</li><li>提供了简单的事务功能，能在一定程度上保证事务特性</li><li>提供了流水线(Pipeline)功能，这样客户端能将一批命令一次性传到 Redis，减少了网络的开销</li></ul><h3 id="持久化"><a href="#持久化" class="headerlink" title="持久化"></a>持久化</h3><ul><li>Redis提供了两种持久化方式:RDB和 AOF，即可以用两种策略将内存的数据保存到硬盘中</li></ul><h3 id="主从复制"><a href="#主从复制" class="headerlink" title="主从复制"></a>主从复制</h3><ul><li>Redis提供了复制功能，实现了多个相同数据的Redis副本(如图1-2所 示)，复制功能是分布式Redis的基础</li></ul>]]></content>
      
      
      <categories>
          
          <category> redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mysql_innodb存储引擎关键特性</title>
      <link href="/2017/05/23/mysql-innodb-cun-chu-yin-qing-guan-jian-te-xing/"/>
      <url>/2017/05/23/mysql-innodb-cun-chu-yin-qing-guan-jian-te-xing/</url>
      
        <content type="html"><![CDATA[<p>本文将简单介绍mysql innodb存储引擎的关键特性；<br>以帮助大家对innodb以及数据库底层的特效有大致的了解并学习其中的设计，方便后续做更深的学习和问题分析；  </p><p>下面参考《mysql技术内幕 InnoDB存储引擎》，分享innodb引擎的关键特性：</p><h4 id="插入缓冲"><a href="#插入缓冲" class="headerlink" title="插入缓冲"></a>插入缓冲</h4><ul><li>innodb基于聚簇索引的时候插入是顺序的，不需要磁盘的随机读写，但是对于非聚簇索引插入不再是顺序的来，性能会下降；</li><li>对于非聚簇索引的插入或更新操作，不是每一次直接插入到索引页中，而是先判断是否再缓冲池种，在，直接插入，不在，先放到insert buffer中，然后根据情况按一定的频率进行buffer和辅助叶子节点的merge操作，就将多个插入合并到一个操作中，可以相应提升性能；</li><li>使用条件：索引是辅助索引， 不是唯一索引；</li><li>Insert Buffer数据结构是一颗b+树，负责所有辅助索引的插入缓存，存放在共享表空间；</li><li>当发现辅助索引页空间不大时，以及Master 进程定期会进行merge Insert Buffer，将其merge仅进物理内存；</li></ul><h4 id="两次写"><a href="#两次写" class="headerlink" title="两次写"></a>两次写</h4><ul><li>doublewrite两部分组成，内存中的buffer以及物理磁盘上的共享表空间的2MB空间；</li><li>对缓冲池的脏页刷新时，会先copy到内存中的doublewrite buffer，然后分两次写入磁盘上，然后调用fsync同步磁盘；</li><li>当写入失效时（如宕机引起），先通过页的副本还原页，然后通过冲入日志重做，就是doublewrite；</li><li>doublewrite带给存储引擎数据也的可靠性；</li></ul><h4 id="自适应哈希"><a href="#自适应哈希" class="headerlink" title="自适应哈希"></a>自适应哈希</h4><ul><li>存储引擎对访问的热点数据构建自适应哈希，提高速度；</li><li>自适应哈希索引是通过缓冲池的B+树页构造而来，建立速度快；</li><li>要求：对某个页的连续访问模式是一样的；</li></ul><h4 id="异步IO"><a href="#异步IO" class="headerlink" title="异步IO"></a>异步IO</h4><ul><li>异步IO可以进行IOmerge， 提升性能；</li></ul><h3 id="刷新邻接页"><a href="#刷新邻接页" class="headerlink" title="刷新邻接页"></a>刷新邻接页</h3><ul><li>当刷新一个脏页时，检测所在区的所有也，如果是脏页，也一起刷新；</li></ul><h4 id="备注"><a href="#备注" class="headerlink" title="备注"></a>备注</h4><ul><li>以上是对innodb存储引擎关键特性的一些介绍，大部分特效都是可以通过配置进行开关的，可以结合实际情况进行调整；</li><li>如两次写，如果我们有其他高效的写失效防范机制，也可以考虑不适用这个特性；</li><li>像异步的这些思想在我们的程序设计中都可以进行参考；</li><li>同意像刷新邻接页的特性，我们在进行概率抽样处理的时候，也可以参考这个思想扩大抽样范围；</li></ul><p>以上是对innodb关键特效的简单介绍，后续会继续进行相关简单和进阶知识的分享，欢迎一起讨论交流~</p>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mysql-innodb存储引擎体系结构介绍</title>
      <link href="/2017/05/22/mysql-innodb-cun-chu-yin-qing-ti-xi-jie-gou-jie-shao/"/>
      <url>/2017/05/22/mysql-innodb-cun-chu-yin-qing-ti-xi-jie-gou-jie-shao/</url>
      
        <content type="html"><![CDATA[<p>  本文简单介绍Innodb存储引擎的体系架构。<br>  Innodb体系内含（参考图）：</p><ul><li>文件系统；</li><li>多个内存块组成的大的内存池；</li><li>后台线程</li></ul><h4 id="文件系统"><a href="#文件系统" class="headerlink" title="文件系统"></a>文件系统</h4><p>   数据存储再磁盘上的最终场所；</p><h4 id="后台线程"><a href="#后台线程" class="headerlink" title="后台线程"></a>后台线程</h4><p>   Innodb是多线程的模型，后台有多个不同的后台线程。</p><ul><li>Master Thread： 核心后台线程，负责将缓冲池中的数据异步刷新到磁盘，保持数据一致性，包括脏页的刷新、合并插入缓冲、UNDO页的回收等；</li><li>IO Thread：Innodb使用AIO来处理IO请求。负责处理io请求的回调；</li><li>Purge Thread：回收已经使用 分配的undo页；</li><li>Page Cleaner Thread： 1.2.x版本引入，将脏页的刷新操作放入单独的线程中完成；减轻Master Thread的工作；</li></ul><h4 id="内存"><a href="#内存" class="headerlink" title="内存"></a>内存</h4><ul><li>缓冲池：Innodb存储引擎虽然是基于磁盘存储，但使用缓冲池来提升性能；缓存查询结果；对于修改操作，先修改缓冲池中的页再异步刷新到磁盘上（checkpoint机制）；</li><li>Innodb缓冲池的管理：使用LRU list，Free List和Flush List；主要可以了解下LRU-最近最少使用算法管理；<br>新数据放在list midpoint的位置；<ul><li>重做日志缓冲：先放到缓冲区，按一定频率刷新到重做日志文件；</li><li>额外的内存池：对内存的管理通过内存堆的方式进行，对一些数据结构本身的内存分配需从额外的内存池中申请；</li><li>checkpoint：前面提到checkpoint，其实就是一种类似定期执行的检查，把一些事情不是无限堆积而是定期执行。checkpoint的目的如下：<ul><li>从checkpoint恢复数据库，缩短故障恢复时间；</li><li>缓冲池不够时将脏页刷新到磁盘；</li><li>重做日志不够时，刷新磁盘；</li></ul></li></ul></li></ul><p>关于Innodb体系的细节以及更多的特性，以及mysql使用中更多的技巧和经验，后续文档会继续更新。<br>若感兴趣推荐阅读《Mysql技术内幕 InnoDB存储引擎》。</p><p>后续会继续分享相关基础和进阶知识，欢迎一起讨论交流~</p>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>java基础学习之string专题</title>
      <link href="/2017/03/23/java-ji-chu-xue-xi-zhi-string-zhuan-ti/"/>
      <url>/2017/03/23/java-ji-chu-xue-xi-zhi-string-zhuan-ti/</url>
      
        <content type="html"><![CDATA[<p>今天介绍下java中的String</p><h3 id="用法"><a href="#用法" class="headerlink" title="用法"></a>用法</h3><ul><li>定义String变量<pre><code>String a = &quot;test&quot;;</code></pre></li><li>new 创建<pre><code>String b = new String(&quot;test&quot;);</code></pre></li><li>可以直接使用+ += 运算</li></ul><h3 id="内部原理"><a href="#内部原理" class="headerlink" title="内部原理"></a>内部原理</h3><ul><li>String类内部用一个字符数组表示字符串</li><li>String会根据参数新创建一个数组，并复制内容，而不会直接用参数中的字符数组。String中的大部分方法内部也都是操作的这个字符数组</li></ul><h3 id="不可变性"><a href="#不可变性" class="headerlink" title="不可变性"></a>不可变性</h3><ul><li>String类也是不可变类，即对象一旦创建，就没有办法修改了。String类也声明为了final，不能被继承，内部char数组value也是final的，初始化后就不能再变了</li><li>String类中提供修改的方法，是通过创建新的String对象来实现的，原来的String对象不会被修改</li></ul><h3 id="常量字符串"><a href="#常量字符串" class="headerlink" title="常量字符串"></a>常量字符串</h3><ul><li>字符串常量放在字符串常量池</li><li>直接使用常量的定义引用的是常量池内同一个对象，相等，new 出来的则是新的对象</li></ul><h3 id="特别说明"><a href="#特别说明" class="headerlink" title="特别说明"></a>特别说明</h3><ul><li>如果频繁修改字符串，而每次修改都新建一个字符串，那么性能太低，这时，应该考虑Java中的另两个类StringBuilder和StringBuffer<br>-</li></ul>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>java基础学习之数据类型</title>
      <link href="/2017/02/17/java-ji-chu-xue-xi-zhi-shu-ju-lei-xing/"/>
      <url>/2017/02/17/java-ji-chu-xue-xi-zhi-shu-ju-lei-xing/</url>
      
        <content type="html"><![CDATA[<p>  java是强类型语言，必须为每一个变量声明一种类型。一共有8种基本类型：</p><h5 id="整型"><a href="#整型" class="headerlink" title="整型"></a>整型</h5><ul><li>int：4字节，（取值范围不在此列出，可google或参考《java核心技术》）</li><li>short：2字节</li><li>long：8字节</li><li>byte：1字节</li></ul><h4 id="浮点类型"><a href="#浮点类型" class="headerlink" title="浮点类型"></a>浮点类型</h4><ul><li>float： 4字节</li><li>double：8字节</li></ul><h4 id="char类型"><a href="#char类型" class="headerlink" title="char类型"></a>char类型</h4><ul><li>char类型</li></ul><h4 id="boolean类型"><a href="#boolean类型" class="headerlink" title="boolean类型"></a>boolean类型</h4><ul><li>booleab类型</li></ul><p>以上是java的基本类型，这里简单扩展一下，java的底层字节码指令。一般是对某种数据类型的某种操作，但是某些数据类型是没有该操作的特定指令，这时候会将该类型转化为其他类型然后进行操作。如：</p><ul><li>大多数对于boolean、byte、short和char类型数据的操作实际上使用相应的int类型作为运算类型；</li><li>大部分的字节码指令都没有支持类型byte char和short；</li></ul><p>本文简单介绍java的基本类型，后续文章会继续整理分享java基础以及进阶知识，欢迎一起讨论交流。</p>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>前后端分离思考</title>
      <link href="/2017/02/17/qian-hou-duan-fen-chi-si-kao/"/>
      <url>/2017/02/17/qian-hou-duan-fen-chi-si-kao/</url>
      
        <content type="html"><![CDATA[<p>本文主要分享对于前后端分离开发模式的思考(讨论的内容和架构关系不大…)。<br>欢迎讨论和吐槽。</p><h3 id="关于前后端分离"><a href="#关于前后端分离" class="headerlink" title="关于前后端分离"></a>关于前后端分离</h3><ul><li>前后端分离是从开发模式进行的前后端分工开发模式，用约定的数据格式(如json)进行交互。</li><li>前端仅需要关心页面，可以自己去对页面进行模板化等操作，而不关心后端数据的任何细节，只依赖<br>提供的交互文档约定的数据格式，然后自己去渲染页面。</li><li>后端也不去关心前端的渲染，只关心数据层和业务逻辑层的建设和优化，怎样更好的吐出数据，如何优化<br>接口性能，如何节约服务器资源；<h3 id="推荐"><a href="#推荐" class="headerlink" title="推荐"></a>推荐</h3></li><li>基于前后端分离的架构，后端是自由的，go，php任何语言工具都可以，只需要按照约定去返回数据即可；</li><li>前端如何渲染则可以自己去考虑，用angular js，Vue等数据绑定？页面模板化？ 都是自己结合业务优化的方向<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3></li><li>前后端分离对于部分仅会html css，js薄弱的前端老说是有压力的，需要学习成本；</li><li>但是习惯之后，可以提高开发效率，让大家专注自己的关注部分，提高开发的规范性。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 架构 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 前后端分离 </tag>
            
            <tag> 架构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>webbench-压测</title>
      <link href="/2016/10/17/webbench-ya-ce/"/>
      <url>/2016/10/17/webbench-ya-ce/</url>
      
        <content type="html"><![CDATA[<p>本文主要和大家分享一个压测工具，webbench，安装和使用都非常方便。<br>欢迎讨论和吐槽。</p><h3 id="使用实例"><a href="#使用实例" class="headerlink" title="使用实例"></a>使用实例</h3><ul><li>下载webbench: wget <a href="http://blog.s135.com/soft/linux/webbench/webbench-1.5.tar.gz" target="_blank" rel="noopener">http://blog.s135.com/soft/linux/webbench/webbench-1.5.tar.gz</a></li><li>解压，安装webbench:<pre class=" language-$xslt"><code class="language-$xslt">tar zxvf webbench-1.5.tar.gzcd webbench-1.5make && make install</code></pre></li><li>应用:<pre class=" language-$xslt"><code class="language-$xslt">webbench -c 300 -t 60 http://***//其中 -c表示并发数， -t表示时间(秒)//返回中的Requests/秒数 = QPS</code></pre><h3 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h3>项目上线之前要做全面的测试，包括压测，这样可以避免很多的问题。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 测试 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 测试 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>高并发架构思考01</title>
      <link href="/2016/10/17/gao-bing-fa-jia-gou-si-kao-01/"/>
      <url>/2016/10/17/gao-bing-fa-jia-gou-si-kao-01/</url>
      
        <content type="html"><![CDATA[<p>本文记录对于高并发web架构的一些经验积累和思考，后续会就此话题继续更新。<br>欢迎讨论和吐槽。</p><h3 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h3><ul><li>作为web开发工作者，高并发的处理是大家比较关心的问题之一。</li><li>php上手简单，开发业务迭代迅速，但是他的性能一直为人们诟病。</li><li>php7发布后，php的性能有了更近一步的提升，但是相对于c++，java来说还存在差距。</li><li>我们可以通过架构满足业务的高并发需求，本文主要基于此点进行讨论和记录。</li><li>作为php的开发者，希望可以为优化他的性能贡献一份力量，现在swoole的思路个人认为是值得学习的思考方向，</li><li>异步和协程的特性使用可以很好的提高性能，更好的利用服务器资源。</li><li>毕竟php底层是基于c实现的，我相信一定可以更好的将c的高性能和php的高效开发特性很好的结合，在大家的努力下。</li></ul><h3 id="高并发的处理思路"><a href="#高并发的处理思路" class="headerlink" title="高并发的处理思路"></a>高并发的处理思路</h3><p>这里简单总结一些处理高并发的架构思路：</p><ul><li>动态页面和静态资源分离</li><li>前端页面的静态化</li><li>多级缓存提高数据响应速度，减轻数据层压力</li><li>业务逻辑异步处理</li><li>数据分库分表，读写分离</li><li>业务分离，业务服务化<br>……</li></ul><p>后续我会附上一个整体的结构图，对以上内容概括和整理</p><h3 id="部分具体实施讨论"><a href="#部分具体实施讨论" class="headerlink" title="部分具体实施讨论"></a>部分具体实施讨论</h3><ul><li>静分离 页面静态化<ul><li>页面上的图片等静态化资源放在单独的服务器，且资源用不同的域名，提升浏览器获取资源的速率；</li><li>利用cdn，服务器文件缓存，yac缓存等进行静态化缓存，减少后端服务的压力(不推荐cdn，cdn节点的刷新效率较慢)；</li><li>数据上动态的部分，可以在服务器层讲静态页面和从缓存获取的动态数据拼接成模板页面，在请求时直接返回给前端；</li></ul></li><li>多级缓存<ul><li>页面的动态数据通过缓存获取，部分数据可以直接存在yac服务本地内存，减少redis服务器通信损耗；</li><li>数据的缓存分为多级，第一级缓存失效，后面可以放置一层惰性非实时更新的缓存，通过定时任务等手段更新，可能数据量和存储结构较上一层</li><li>缓存数据而言更大更不精准。目的是尽可能的是减少直接访问db的频率；</li><li>可以直接使用内存+磁盘的存储模式，所有数据读取来自内存（如yac），写入的时候会异步写入多处磁盘进行备份；</li></ul></li><li>业务异步处理<ul><li>如使用php的swoole框架将业务更好的分离，提升代码层的执行效率，现在很多编程语言如go都是自带异步和协程的处理特性；</li><li>对于耗时的业务做一些特殊处理，如异步，使用长连接等；</li></ul></li><li>数据层优化<ul><li>高并发的业务往往以为着大数据，db层的瓶颈往往影响整个业务，常用的有合理的分库分表的措施；</li><li>读写分离</li><li>集群优化</li><li>数据监控，监控数据库服务压力<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3></li></ul></li><li>高并发场景复杂且多样化，需要根据业务的具体情况有重点的去调整架构；</li><li>有时候对于很大的请求需求，不得不进行服务降级，减少部分服务质量和少数用户的体验换取业务的可用，下篇会举例讨论。</li><li>后续会继续讨论此问题，并加上详细的处理经历与大家分享。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 架构 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 架构 </tag>
            
            <tag> 高并发 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>故事-睡前检查</title>
      <link href="/2016/10/17/gu-shi-shui-qian-jian-cha/"/>
      <url>/2016/10/17/gu-shi-shui-qian-jian-cha/</url>
      
        <content type="html"><![CDATA[<p>两鬓微白的父亲慈爱的看着床上躺着的4岁的儿子，像往常一样轻声为他读着睡前故事。<br>还是一样的故事，孩子却不像往常一样，依然精神奕奕。<br>父亲还没有摆脱白天工作的疲惫，轻吻儿子的额头。<br>“该睡觉啦。”<br>“好的，daddy。”<br>父亲起身，走到门口欲关灯出去。<br>儿子嘲弄般地笑看着父亲，<br>“daddy,你还没有检查床底呢”<br>睡前故事，亲吻额头，检查床底，是父亲每天睡前都会做的三件事。<br>“好的，亲爱的。”<br>父亲依旧慈爱的声音，漫步走到床边，可能是怕动静太大，可能是白天比较疲劳，他缓缓的弯腰看向床底。<br>床底稍微有点暗，因为房间的灯还亮着所以依旧看得清晰。<br>床下，正躺着自己的儿子。<br>可能因为害怕，可能因为委屈，小脸憋得有点红。<br>儿子也看向自己，发出很轻很轻的喃呢。<br>“daddy,我的床被抢了”<br>眨巴着委屈的眼睛。<br>父亲的后背微微发凉，说不出话……</p>]]></content>
      
      
      <categories>
          
          <category> 故事 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 恐怖故事 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>thinkphp文件静态缓存学习</title>
      <link href="/2016/08/19/thinkphp-wen-jian-jing-tai-huan-cun-xue-xi/"/>
      <url>/2016/08/19/thinkphp-wen-jian-jing-tai-huan-cun-xue-xi/</url>
      
        <content type="html"><![CDATA[<p>本文分享使用thinkphp框架自带的静态缓存实现文件静态化。<br>欢迎讨论和吐槽。</p><h3 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h3><ul><li>使用的场景是访问活动页面的时候希望进行静态化处理，提升请求效率；</li><li><p>页面静态化有多种解决方案，如使用yac保存在内存中，本文分享的是使用tp自带的缓存功能生成静态化的html文件（可以是其他文件）。</p><h3 id="操作"><a href="#操作" class="headerlink" title="操作"></a>操作</h3><p>使用此功能是比较简单，步骤如下(基于tp3.2)：</p></li><li><p>conf中配置开启静态缓存</p><pre class=" language-$xslt"><code class="language-$xslt">'HTML_CACHE_ON'=>true,//静态化相关 'HTML_CACHE_TIME'   =>    60,   // 全局静态缓存有效期（秒） 'HTML_FILE_SUFFIX'  =>    '.html', // 设置静态缓存文件后缀 'HTML_CACHE_RULES'=> array(     'index:commonindex' => array('{act}', '60'),  //缓存规则 ),</code></pre><p>缓存规则有多种配置方式，可<a href="http://document.thinkphp.cn/manual_3_2.html#html_cache" target="_blank" rel="noopener">参考文档</a>。</p></li><li><p>确认HTML_PATH的路径配置，确认此路径文件夹存在：</p><pre class=" language-$xslt"><code class="language-$xslt">defined('HTML_PATH')    or define('HTML_PATH',      APP_PATH.'Html/'); // 应用静态目录</code></pre><h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><p>这里阐述下分享过程中遇到的问题：</p></li></ul><ol><li>确保HTML_PATH指定的文件夹存在</li><li>配置的规则方法要用小写，如commonindex(未测试commonIndex是否可以)；</li><li>tp的缓存需要基于display加载的view文件，没有加载view文件直接输入内容无法生成缓存。<h3 id="思考和总结"><a href="#思考和总结" class="headerlink" title="思考和总结"></a>思考和总结</h3></li></ol><ul><li>使用tp自带的缓存功能实现文件静态化比较简单的；</li><li>但是其中也有些限制，在问题模块大致阐述，还可以用以下方案替代：<ol><li>将html内容存在内存(如使用yac，redis)，请求的时候先拿缓存直接输出；</li><li>访问到页面后生成html文件放在服务器某目录，下一次访问在进入项目之前判断存在此文件则直接走缓存文件；</li></ol></li><li>页面静态化的时候，如果页面有内容是需要动态加载的，对于数据少的可以加载页面完了用ajax请求去更新，更好的方法是<br>在服务器端取出静态文件的时候就去更新拼接态内容，这样前端看不到一个刷的过程。</li></ul>]]></content>
      
      
      <categories>
          
          <category> php </category>
          
      </categories>
      
      
        <tags>
            
            <tag> php </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>swoole-学习使用中遇到的问题记录</title>
      <link href="/2016/07/13/swoole-xue-xi-shi-yong-zhong-yu-dao-de-wen-ti-ji-lu/"/>
      <url>/2016/07/13/swoole-xue-xi-shi-yong-zhong-yu-dao-de-wen-ti-ji-lu/</url>
      
        <content type="html"><![CDATA[<p>本文分享自己在学习使用swoole中遇到的一些问题，在此记录。<br>欢迎讨论和吐槽。</p><h3 id="疑问-思考"><a href="#疑问-思考" class="headerlink" title="疑问-思考"></a>疑问-思考</h3><ul><li>我们使用swoole server的时候，在前面是否需要设置nginx代理等；</li><li>使用swoole中设置worker进程，设置几个比较合适？<ul><li>个人感觉应该根据业务量级来设置</li></ul></li><li>swoole server 启动后，如何监控启动的server<ul><li>server运动长时间后可能会服务异常，变成僵尸进程，目前我知道的做法可以定时重启swoole进程</li></ul></li><li>swoole server代码更新后如何软重启<ul><li>目前我知道只能直接关闭后重新启动，建议是可以检测将没有处理完请求的worker进程关闭，然后杀死，重新启动，逐个worker进程重启<br>实现软重启。<br>###总结<br>只是个人在使用中遇到的一些问题和思考，后续有更多问题和更好的解答会在此更新。</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> php </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 问题记录 </tag>
            
            <tag> php </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>php文件输出空行</title>
      <link href="/2016/06/17/php-wen-jian-shu-chu-kong-xing/"/>
      <url>/2016/06/17/php-wen-jian-shu-chu-kong-xing/</url>
      
        <content type="html"><![CDATA[<p>本文分享一次开发中遇到的文件输出空行的问题以及原因。<br>欢迎讨论和吐槽。</p><h3 id="文件输出空行的问题"><a href="#文件输出空行的问题" class="headerlink" title="文件输出空行的问题"></a>文件输出空行的问题</h3><p>一个公共类，用来输出json数据，只要调用这个类中的方法输出，在输出json数据前面多出空行</p><p>###问题原因和解决方法</p><ul><li>使用之前的版本没有这个问题，经过版本对比，发现修改的过程中，在php结束标志的地方?&gt;后面不小心添加了几个空行；</li><li>然后再请求这个文件输出的时候，会在最前面多出几个空行（并没有影响json的解析）;<pre class=" language-$xslt"><code class="language-$xslt">?></code></pre></li><li>去掉文件中的空行后，问题解决。</li></ul><h3 id="问题总结"><a href="#问题总结" class="headerlink" title="问题总结"></a>问题总结</h3><ul><li>针对这种输出额外空行的问题，除了检查文件中是否有额外的空行，还可能是文件编码造成的：如果是notepad编写的php文件，会统一添加UTF-8 + BOM，造成php文件的输出有空行。保存成其他不包含BOM头的编码格式可以解决。</li><li>可以通过脚本检查自己的php文件是否包含空行，将以下脚本放在文件目录下，执行以下脚本查看。<pre class=" language-$xslt"><code class="language-$xslt"><?phpif (isset($_GET['dir'])){//config the basedir  $basedir=$_GET['dir'];}else{    $basedir = '.';}$auto = 1;checkdir($basedir);function checkdir($basedir){  if ($dh = opendir($basedir)) {      while (($file = readdir($dh)) !== false) {          if ($file != '.' && $file != '..'){              if (!is_dir($basedir."/".$file)) {                  echo "filename: $basedir/$file ".checkBOM("$basedir/$file")." <br>";              }else{                  $dirname = $basedir."/".                      $file;                  checkdir($dirname);              }              }      }      closedir($dh);      }}function checkBOM ($filename) {  global $auto;  $contents = file_get_contents($filename);  $charset[1] = substr($contents, 0, 1);  $charset[2] = substr($contents, 1, 1);  $charset[3] = substr($contents, 2, 1);  if (ord($charset[1]) == 239 && ord($charset[2]) == 187 &&      ord($charset[3]) == 191) {      if ($auto == 1) {          $rest = substr($contents, 3);          return ("<font color=red>BOM found,automatically removed.</font>");      } else {          return ("<font color=red>BOM found.</font>");      }      }  else return ("BOM Not Found.");}?></code></pre></li></ul>]]></content>
      
      
      <categories>
          
          <category> php </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 问题记录 </tag>
            
            <tag> php </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>jquery-autocompleter使用介绍</title>
      <link href="/2016/04/17/jquery-autocompleter-shi-yong-jie-shao/"/>
      <url>/2016/04/17/jquery-autocompleter-shi-yong-jie-shao/</url>
      
        <content type="html"><![CDATA[<p>本文分享使用jquery-autocompleter模板。<br>欢迎讨论和吐槽。</p><h4 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h4><p>在业务中遇到需求希望可以在输入框中输入游戏名称的一部分，然后自动补全出含游戏id-游戏名称的下拉选项供选择。</p><h4 id="使用案列"><a href="#使用案列" class="headerlink" title="使用案列"></a>使用案列</h4><ul><li>业务中的实现代码如下：<pre class=" language-$xslt"><code class="language-$xslt">var game_id_names = '';   $.ajax({       dataType:'json',       url : 'URL',       async:false,//这里选择异步为false，那么这个程序执行到这里的时候会暂停，等待                   //数据加载完成后才继续执行       success : function(data){           for(var i=0;i<data.length;i++){               var str = '"'+data[i].gameid+','+data[i].gamename+'"';               game_id_names += '{"label":'+str+'},';           }       }   });   game_id_names = eval('['+game_id_names+']');   $('#nope').autocompleter({       // marker for autocomplete matches       highlightMatches: true,       // object to local or url to remote search       source: game_id_names,       // custom template       template: '{{ label }}',       // show hint       hint: true,       // abort source if empty field       empty: false,       // max results       limit: 20,   });});</code></pre></li><li>这里分享一个可查看效果的代码样例：<pre><code>&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt;  &lt;meta charset=&quot;UTF-8&quot;&gt;  &lt;title&gt;Title&lt;/title&gt;  &lt;link rel=&quot;stylesheet&quot; href=&quot;normalize.css&quot;&gt;  &lt;link rel=&quot;stylesheet&quot; href=&quot;mains.css&quot;&gt;  &lt;script type=&quot;text/javascript&quot; src=&quot;http://img.qidian.com/js/jquery-2.1.1.min.js&quot;&gt;&lt;/script&gt;  &lt;script src=&quot;jquery.autocompleter.js&quot;&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;测试输入框&lt;input id=&quot;test-input&quot; placeholder=&quot;请输入水果&quot; maxlength=&quot;40&quot; /&gt;&lt;/body&gt;&lt;script &gt;  $(function(){      var fruits = eval(&quot;[{&#39;label&#39;:&#39;西瓜&#39;},{&#39;label&#39;:&#39;火龙果&#39;},{&#39;label&#39;:&#39;西瓜2&#39;},{&#39;label&#39;:&#39;西瓜3&#39;}, {&#39;label&#39;:&#39;西瓜4&#39;},{&#39;label&#39;:&#39;苹果&#39;},{&#39;label&#39;:&#39;苹果7&#39;}]&quot;);      $(&#39;#test-input&#39;).autocompleter({          // marker for autocomplete matches          highlightMatches: true,          // object to local or url to remote search          source: fruits,          // custom template          template: &#39;{{ label }}&#39;,          // show hint          hint: true,          // abort source if empty field          empty: false,          // max results          limit: 20,      });  });&lt;/script&gt;&lt;/html&gt;</code></pre></li></ul><h4 id="使用交流"><a href="#使用交流" class="headerlink" title="使用交流"></a>使用交流</h4><p>使用autocompleter模板需要引入jquery.autocompleter.min.js；<br>引入jquery.autocompleter.css（不然效果难看）；</p><p>效果还是不错的，已上实例是非常基本简单的使用，还有更方便、强大的使用方式希望一起交流。</p><h4 id="参考地址"><a href="#参考地址" class="headerlink" title="参考地址"></a>参考地址</h4><p><a href="http://www.jq22.com/jquery-info438" target="_blank" rel="noopener">jQuery自动完成插件autocompleter</a></p>]]></content>
      
      
      <categories>
          
          <category> jquery </category>
          
      </categories>
      
      
        <tags>
            
            <tag> jquery </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>git-代码开发发布流程</title>
      <link href="/2016/04/17/git-dai-ma-kai-fa-fa-bu-liu-cheng/"/>
      <url>/2016/04/17/git-dai-ma-kai-fa-fa-bu-liu-cheng/</url>
      
        <content type="html"><![CDATA[<p>本文讨论业务接触到的git发布流程，在此记录和分享。<br>欢迎讨论和吐槽。</p><h4 id="方案1"><a href="#方案1" class="headerlink" title="方案1"></a>方案1</h4><p>这是在我第一家公司的经验，刚开始我们团队的发布系统是内部的发布系统，而后使用的是jenkins发布。<br>以下流程为文字描述，希望可以描述清楚。<br>公司开发分本地，测试，预发，线上环境，相应的项目有master，develop，test远程分支。</p><ol><li>本地pull develop和test分支，在develop分支上切出a分支进行功能开发，在本地环境测试；</li><li>本测试完毕，更新本地test分支，将a分支合并到test，推送远端，然后放到测试环境(这样可以满足多个开发在同一个测试环境测试);</li><li>测试环境测试ok，更新本地develop，合并a分支（有冲突合作解决冲突），推送，然后发到预发环境测试。</li><li><p>预发环境测完后发布上线（用的master分支，开发只有推送远端develop的权限，合并master只有权限更高的人可操作）。</p><h4 id="方案2"><a href="#方案2" class="headerlink" title="方案2"></a>方案2</h4><p>这是我第二家公司了解的发布流程。<br>同样，公司分本地，测试，预发，线上环境，项目有master，develop分支远程分支。</p></li><li><p>开发a拥有远端a分支，用户本地开发，本地测试。</p></li><li>本地测试完成，代码合并推送远端a分支，a拥有自己的测试环境，a分支代码如测试环境1测试，和别人的并行功能互不影响；</li><li>测试环境测试完毕，a代码合并入预发，简单验证后上线。此时可能会同时两个人需要发预发，但是到这一步因流程较快，进行串行操作，a验证完了b才能合进来验证；</li><li>预发确认完毕，上线。</li></ol><h4 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h4><p>两种方案都解决了一定的问题，也都还存在瑕疵。<br>前者开发发布不受别人影响可以在统一环境测试，但是因为在同一环境，测试中还是可能有问题；<br>后者发布测试环境独立，但是预发环境串行可能效率存在问题，而且后一个人的代码和前一个人没有一起在测试环境验证，到了预发合并后，可能存在问题（对前者）。</p>]]></content>
      
      
      <categories>
          
          <category> git </category>
          
      </categories>
      
      
        <tags>
            
            <tag> git </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>最大子序列和问题求解</title>
      <link href="/2016/03/17/zui-da-zi-xu-lie-he-wen-ti-qiu-jie/"/>
      <url>/2016/03/17/zui-da-zi-xu-lie-he-wen-ti-qiu-jie/</url>
      
        <content type="html"><![CDATA[<p>本系列主要整理分享对一些数据结构和算法问题的总结和思考，供基础相对较差的人渐进地学习，也是自身复习和寻求提升的过程。(代码部分借鉴和取自数据结构和算法书籍)<br>本文主要分享对最大子序列求和问题的求解和思考。<br>欢迎讨论和吐槽。</p><h3 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h3><ol><li>给定整数A1，A2…An(包含负数），求某一段(从第i个到第j个）的数字之和的最大值。</li><li>约定：所有整数均为负数，最大值为0(降低复杂度)</li><li>例： 1，-3,3，-2，5，-6，其中最大值是3 到5 ，和为6.<h3 id="问题分析"><a href="#问题分析" class="headerlink" title="问题分析"></a>问题分析</h3></li></ol><ul><li>例子中的数字较少，我们可以直观的观察就得出结论，这其实是变相的穷举法。</li><li>根据问题的分析，我们可以得到下面两个结论<ul><li>若前面的和为最大值，下一个数或者接下来n个数为整数，则接下来几个数应该被算进去；</li><li>若两段的和都为正数，无法合在一起，取和较大的一串。<h3 id="求解思路"><a href="#求解思路" class="headerlink" title="求解思路"></a>求解思路</h3>这里分享3个解决的思路和算法实现(代码为C)。</li></ul></li></ul><ol><li>穷举和，找到最大的结果。<pre class=" language-$xslt"><code class="language-$xslt">int max(int data[], int length) {int sum,maxSum,i,j;maxSum = 0;for(i=0;i<length;i++) { sum = 0;              //依次以某个位置为起点for(j=i;j<length;j++) { sum += data[j];       //逐个叠加计算找到某起点下的最大和 if(sum>maxSum) {   maxSum = sum; }}}return maxSum;}</code></pre></li><li>接来下的方法很好的使用了递归这个武器，上面的方法1比较直观，很容易想到，但是穷举法的效率一般是不高的，我们<br>可以使用分治策略，把问题化小去解决。<br>针对这个问题最核心的思路是这样的：<ul><li>这个序列分为两部分，分别求出左半部分的最大和，右半边的最大和，还有一种可能是结果在两部分中，因为序列是连续的，这种情况下必然包含左边的最后一个元素和右边的第一个元素，然后我们以这两点为起点一直计算下可以得到这种情况下的最大值，将三个最大值进行比较得到最大值即为最后的结果。</li><li>分出的两部分也递归的用上面的思想求出最大值。<pre class=" language-$xslt"><code class="language-$xslt">int max(int data[],int left,int right) {int maxLeftSum,maxRightSum;int maxLeftPart,maxRightPart,leftPartSum,rightPartSum,center,i;if(left==right) {              //分到最小结果的返回if(data[left]>0) { return data[left];} else { return 0;}}center = (left+right)/2;maxLeftSum = max(data,left,center);  //左半部分的最大和maxRightSum = max(data,center+1,right); //右半部分的最大和maxLeftPart = 0;leftPartSum = 0;for(i = center;i>=left;i++) {leftPartSum += data[i];if(leftPartSum>maxLeftPart) {maxLeftPart = leftPartSum;}}maxRightPart = 0;rightPartSum = 0;for(i = center+1;i<=left;i++) {rightPartSum += data[i];if(rightPartSum>maxRightPart) {  maxRightPart = rightPartSum;}}maxCenterSum = maxRightPart+maxLeftPart;return  ;       //返回三个最大值中的最大值}</code></pre>3.这个方法是针对本题目的一种灵活的解法：</li><li>我们每新加一个数，若和增大，则更新最大和；</li><li>若最大和大于0，则继续基于此最大和进行判断，若小于0，则对于后面的序列而言前面应该舍弃，此时从下个元素开始从新开始查找结果与前面的最大和进行比较；</li><li>这个方案的思路简单来说是从第一个元素，然后每次增加一个元素，判断增加前的最大和，与增加后的和比较，然后得出最大值<pre class=" language-$xslt"><code class="language-$xslt">int max(int data[],int length) {int sum,maxSum,i;sum = maxSum = 0;for(i=0; i<length; i++ ){sum += data[i];if(sum>maxSum) { maxSum = sum;} else if(sum<0) { sum = 0;               //从下一个元素开始重新计算}}}</code></pre></li></ul></li></ol><h3 id="总结-amp-思考"><a href="#总结-amp-思考" class="headerlink" title="总结&amp;思考"></a>总结&amp;思考</h3><ul><li>遇到问题应该多思考，判断和分析问题，找到解决问题的思路；</li><li>穷举法可以作为一个思路，但是一般效率较差；</li><li>分治法是很好的策略，将问题大二化小。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 数据结构与算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据结构与算法 </tag>
            
            <tag> 算法题 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>列表项实现上下移动</title>
      <link href="/2016/02/17/lie-biao-xiang-shi-xian-shang-xia-yi-dong/"/>
      <url>/2016/02/17/lie-biao-xiang-shi-xian-shang-xia-yi-dong/</url>
      
        <content type="html"><![CDATA[<p>本文分享解决一个对一组列表项点击上下移动修改其排序位置的问题。<br>欢迎讨论和吐槽。</p><h3 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h3><ul><li>这个问题其实很简单，实现的方式也不止一种，这里主要分享我实现的方法；</li><li>问题是有一列选项，按一定顺序显示，可以通过上下移动修改其显示顺序；</li><li>顺便说一句，曾经有一次面试，面试官问我的就是这个问题，当时并没有回答出来。 = =<h3 id="问题解决"><a href="#问题解决" class="headerlink" title="问题解决"></a>问题解决</h3>这里我当时的考虑是加一个字段order用来排序，觉得上移就减少这个order值，下移就增加这个值，按照这个思考就有点复杂；<br>还是根据这个思路，后来的实现是在移动过滤中，交换应该和它交换的项的order值，就可以实现排序，参考下方：<pre class=" language-$xslt"><code class="language-$xslt">order1B  order2C  order3</code></pre>C上移:<pre class=" language-$xslt"><code class="language-$xslt">A  order1B  order3C  order2</code></pre>这样根据order排序显示就可以达到显示目的。</li></ul><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ul><li>这个问题不难，关键要实现的巧妙，单独添加字段用来排序，不影响原有功能。</li><li>继续思考其他方案</li></ul>]]></content>
      
      
      <categories>
          
          <category> php </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 问题记录 </tag>
            
            <tag> php </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>记录一次nginx-server返回502的问题排查</title>
      <link href="/2016/01/17/ji-lu-yi-ci-nginx-server-fan-hui-502-de-wen-ti-pai-cha/"/>
      <url>/2016/01/17/ji-lu-yi-ci-nginx-server-fan-hui-502-de-wen-ti-pai-cha/</url>
      
        <content type="html"><![CDATA[<p>本文记录一次自己在配置nginx+php-fpm时候遇到的问题，访问nginx server一直返回502。<br>欢迎讨论和吐槽。</p><h3 id="问题原因"><a href="#问题原因" class="headerlink" title="问题原因"></a>问题原因</h3><ul><li>这个问题对我来说是由于粗心造成，不过大家以后可能会遇到，我这边分享出来。</li><li>当时我在自己的php.ini中添加因为swoole扩展<pre class=" language-$xslt"><code class="language-$xslt">extension=swoole.so</code></pre></li><li>重启php-fpm<pre class=" language-$xslt"><code class="language-$xslt">service php-fpm restart</code></pre></li><li>然后我这边添加了个nginx server，重启了nginx<pre><code>nginx -tnginx -s reload</code></pre></li><li>问题出现了，访问原先正常的站点直接502.<h3 id="问题解决"><a href="#问题解决" class="headerlink" title="问题解决"></a>问题解决</h3></li><li>我第一反应是自己添加的server配置出问题，删除掉，重启nginx，没有用</li><li>在网上查找，大部分都是是因为配置问题，如进程数配置小了，不过这些问题可能生产环境会遇到，我这个是自己的测试环境，应该不会出现这些问题。网上很多解答</li><li>查看nginx log ，发现提示connect fail （111 connect refused）</li><li>在网上找到一个类似的问题：connect refused<pre class=" language-$xslt"><code class="language-$xslt">location ~ \.php {         root  /data/danmu-demo-master;         fastcgi_pass   127.0.0.1:9000;         #fastcgi_pass  unix:/dev/shm/php7.sock;         fastcgi_index  index.php;         fastcgi_param  SCRIPT_FILENAME  $document_root$fastcgi_script_name;         fastcgi_split_path_info  ^(.+\.php)(/.*)$;         fastcgi_param  PATH_INFO $fastcgi_path_info;         include        fastcgi_params;     }</code></pre></li><li>在我的php-fpm中配置的是<pre class=" language-$xslt"><code class="language-$xslt">listen = /dev/shm/php7.sock</code></pre></li><li>我把php-fpm中配置改为<pre class=" language-$xslt"><code class="language-$xslt">listen = 9000</code></pre></li><li>重启fpm，问题解决！</li></ul><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ul><li>nginx+php-fpm的配置有很多需要注意的地方，遇到问题结合日志，以及网上的答案排查问题；</li><li>nginx返回502的原因有很多很多种，大家遇到问题最好记录下来，这就是所谓的经验。</li></ul><h3 id="延伸"><a href="#延伸" class="headerlink" title="延伸"></a>延伸</h3>]]></content>
      
      
      <categories>
          
          <category> nginx </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 问题记录 </tag>
            
            <tag> nginx </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ajax-jsonp请求学习</title>
      <link href="/2016/01/17/ajax-jsonp-qing-qiu-xue-xi/"/>
      <url>/2016/01/17/ajax-jsonp-qing-qiu-xue-xi/</url>
      
        <content type="html"><![CDATA[<h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><p>在ajax请求jsonp获取跨域接口数据的时候，发现以下两个问题</p><ol><li>在chrome的调试处发现js报错提示：success_jsonpCallback function not found</li><li>接口返回json数据为a，console.log显示结果为b<br>当时的ajax请求代码如下：<pre class=" language-$xslt"><code class="language-$xslt">$.ajax({        url:"****",        data:{},        dataType :"jsonp",        jsonp:"callback",        jsonpCallback:"success_jsonpCallback",        type:"POST",        success:function(res) {          console.log(res)        }</code></pre>后端接口返回数据如下：<pre class=" language-$xslt"><code class="language-$xslt">echo "success_jsonpCallback" ."(".jsonData.")";</code></pre>当时是在页面加载的时候就请求获取数据(一共有两个请求-这也是问题的关键所在)<h3 id="解决过程"><a href="#解决过程" class="headerlink" title="解决过程"></a>解决过程</h3><h4 id="尝试一"><a href="#尝试一" class="headerlink" title="尝试一"></a>尝试一</h4></li></ol><ul><li>因为页面还有点击按钮时候做ajax-jsonp请求，是正常的，所以仔细对比了请求的代码，未发现差异，返回的数据格式进行对比也正常；</li><li>然后发现出问题的ajax请求返回数据较长，然后调试换上一样的返回，问题依然存在。<h4 id="尝试二"><a href="#尝试二" class="headerlink" title="尝试二"></a>尝试二</h4></li><li>在网上查阅大量资料后，发现也曾遇到这个问题，没有能解决我遇到的问题；</li><li>尝试给请求做同步请求，问题依然存在<br><code>`</code>$xslt<br>async:false,</li></ul><pre><code>#### 尝试三- 将页面其中一个ajax请求注释，刷新页面，问题解决。### 总结- 整理了代码，继续查阅了一些资料，总结问题如下：页面加载时发起两次ajax请求，但是定义的callback方法是一样的，这样导致异常。- 我遇到问题的解决方法有两种   1. 将两次请求数据放到一个接口返回，只做一次ajax请求   2. ajax请求不规定回调方法名，生成随机回调方法名，可以解决此问题（更优）- 修改后代码如下：ajax请求：```$xslt$.ajax({      url:&quot;**&quot;,      data:{},      dataType :&quot;JSONP&quot;,      type:&quot;GET&quot;,      success:function(activeData) {          //      }  });</code></pre><p>后端返回如下：</p><pre class=" language-$xslt"><code class="language-$xslt">echo $callback ."(".$rd->getJson().")";  //callback通过参数接受</code></pre><p>这里第一次代码中callback写死是很不推荐的（我这么做是测试阶段基于其他原因），但是问题的关键在于不能写死同一个回调方法名（当可能同时出现多个请求回调时）。</p><ul><li>遇到问题要善于思考和排查，以及利用网上的资源。</li><li>这里关于jquery ajax请求的实现原理和问题的真正原因稍后会进行补充。</li></ul>]]></content>
      
      
      <categories>
          
          <category> ajax </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ajax </tag>
            
            <tag> 问题记录 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>linux下安装nginx_mysql_php</title>
      <link href="/2016/01/01/linux-xia-an-zhuang-nginx-mysql-php/"/>
      <url>/2016/01/01/linux-xia-an-zhuang-nginx-mysql-php/</url>
      
        <content type="html"><![CDATA[<p>本文分享下安装lnmp环境的详细步骤。<br>欢迎讨论和吐槽。</p><h3 id="简单说明"><a href="#简单说明" class="headerlink" title="简单说明"></a>简单说明</h3><ul><li>本文是基于Centos 7，于命令行下安装php7+nginx+mysql;</li><li>其中php+nginx的安装步骤来自我的好朋友以及是我的前公司开发组组长的分享（很帅技术很强），亲测ok；</li><li>mysql的安装是基于网上的博客分享。<h3 id="php-nginx安装"><a href="#php-nginx安装" class="headerlink" title="php+nginx安装"></a>php+nginx安装</h3><pre class=" language-$xslt"><code class="language-$xslt">yum update --skip-broken//安装相关依赖库yum -y install php-mcrypt libmcrypt libmcrypt-devel libxml2-devel openssl-devel libcurl-devel libjpeg.x86_64 libpng.x86_64 freetype.x86_64 libjpeg-devel.x86_64 libpng-devel.x86_64 freetype-devel.x86_64 libjpeg-turbo-devel libmcrypt-devel mysql-devel libicu-devel glibc-headers libxslt-devel gcc-c++ pcre-develmkdir ~/Soft && cd Softwget http://jaist.dl.sourceforge.net/project/mcrypt/Libmcrypt/2.5.8/libmcrypt-2.5.8.tar.gztar zxvf libmcrypt-2.5.8.tar.gzcd libmcrypt-2.5.8./configuremake && make installcd ..//卸载预装PHPyum remove phprpm -qa | grep php | xargs rpm -e// 编译安装PHP7.0.9wget http://cn2.php.net/distributions/php-7.0.9.tar.gztar zxvf php-7.0.9.tar.gzcd php-7.0.9./configure --prefix=/usr/local/php --with-config-file-path=/etc/php --enable-fpm --with-fpm-user=webid --with-fpm-group=webid --enable-mysqlnd --with-mysqli=mysqlnd --with-pdo-mysql=mysqlnd --with-iconv-dir --with-freetype-dir=/usr/local/freetype --with-jpeg-dir --with-png-dir --with-zlib --with-libxml-dir=/usr --enable-xml --disable-rpath --enable-bcmath --enable-shmop --enable-sysvsem --enable-inline-optimization --with-curl --enable-mbregex --enable-mbstring --enable-intl --enable-pcntl --with-mcrypt --enable-ftp --with-gd --enable-gd-native-ttf --with-openssl --with-mhash --enable-pcntl --enable-sockets --with-xmlrpc --enable-zip --enable-soap --with-gettext --disable-fileinfo --enable-opcache --with-xsl --enable-sysvmsg --with-imap-sslmake && make install// 建立软连接ln -s /usr/local/php/bin/php /usr/bin/phpmkdir /etc/phpcp php.ini-production /etc/php/php.inicp sapi/fpm/init.d.php-fpm /etc/init.d/php-fpmchmod +x /etc/init.d/php-fpmcp /usr/local/php/etc/php-fpm.conf.default /usr/local/php/etc/php-fpm.confgroupadd webiduseradd -s /sbin/nologin -g webid webidcp /usr/local/php/etc/php-fpm.d/www.conf.default /usr/local/php/etc/php-fpm.d/www.confcd ..// 安装redis扩展wget -c https://github.com/phpredis/phpredis/archive/php7.zipunzip php7.zipcd phpredis-php7//usr/local/php/bin/phpize//执行上一步如果出现“Cannot find autoconf”，则需要执行yum install m4yum install autoconf/usr/local/php/bin/phpize./configure --with-php-config=/usr/local/php/bin/php-configmake && make installcd ..// vim /etc/php/php.ini// extension=redis.soservice php-fpm restart// 安装swoole扩展wget -c https://github.com/swoole/swoole-src/archive/1.8.7-stable.tar.gztar zxvf 1.8.7-stable.tar.gzcd swoole-src-1.8.7-stable//usr/local/php/bin/phpize./configure --with-php-config=/usr/local/php/bin/php-configmake && make installcd ..// vim /etc/php/php.ini// extension=swoole.soservice php-fpm restart//安装nginxwget http://nginx.org/download/nginx-1.10.1.tar.gztar zxvf nginx-1.10.1.tar.gzcd nginx-1.10.1./configure --user=webid --group=webid --prefix=/usr/local/nginx --with-http_stub_status_module --with-http_ssl_module --with-http_v2_module --with-http_gzip_static_module --with-ipv6 --with-http_sub_modulemake && make installcd ..ln -s /usr/local/nginx/sbin/nginx /usr/sbin/nginxln -s /usr/local/nginx/conf /etc/nginxmkdir /usr/local/nginx/conf/vhost// 配置优化vim /usr/local/php/etc/php-fpm.d/www.conflisten = /dev/shm/php7.sockchown webid:webid /dev/shm/php7.sock// 开机启动chmod +x /etc/init.d/php-fpmchkconfig --add /etc/init.d/php-fpmchkconfig php-fpm on// 创建文件 /etc/init.d/nginxchmod +x /etc/init.d/nginxchkconfig --add /etc/init.d/nginxchkconfig nginx onmkdir -p /data/logs/www/nginxmkdir -p /data/webserverpassenger + nginx 安装(Centos 7)yum install -y epel-release yum-utilsyum-config-manager --enable epelsudo yum install -y pygpgme curlsudo curl --fail -sSLo /etc/yum.repos.d/passenger.repo https://oss-binaries.phusionpassenger.com/yum/definitions/el-passenger.repoyum install -y nginx passengersystemctl start nginx.servicegitlab install (centos 7 )yum install curl policycoreutils openssh-server openssh-clientssystemctl enable sshdsystemctl start sshdyum install postfixsystemctl enable postfixsystemctl start postfixfirewall-cmd --permanent --add-service=httpsystemctl reload firewalldcurl -sS https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.rpm.sh | sudo bashsudo yum install gitlab-cegitlab-ctl reconfigure</code></pre></li></ul><h3 id="mysql安装"><a href="#mysql安装" class="headerlink" title="mysql安装"></a>mysql安装</h3><p>可以参考这个教程，步骤比较详细：<a href="http://www.cnblogs.com/fnlingnzb-learner/p/5830622.html" target="_blank" rel="noopener">安装mysql</a></p><h3 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h3><p>我在刚开始搭建环境的时候遇到过问题，基本网上一搜都能找到答案；<br>自己使用推荐的php+nginx安装命令是安装成功的。</p>]]></content>
      
      
      <categories>
          
          <category> php </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
            <tag> php </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>php魔术方法__call的使用</title>
      <link href="/2015/12/12/php-mo-zhu-fang-fa-call-de-shi-yong/"/>
      <url>/2015/12/12/php-mo-zhu-fang-fa-call-de-shi-yong/</url>
      
        <content type="html"><![CDATA[<p>本篇主要简单介绍php魔术方法__call的作用，并提供一个应用场景，分享对此方法的使用心得。<br>欢迎讨论和吐槽。</p><h3 id="call方法简介"><a href="#call方法简介" class="headerlink" title="__call方法简介"></a>__call方法简介</h3><p>为了避免当调用的方法不存在时产生错误，可以使用 __call() 方法。该方法在调用的方法不存在时会自动调用，程序仍会继续执行下去。详见文档：<a href="http://php.net/manual/zh/language.oop5.overloading.php#object.call" target="_blank" rel="noopener">php魔术方法</a></p><h3 id="call使用分享"><a href="#call使用分享" class="headerlink" title="__call使用分享"></a>__call使用分享</h3><ul><li>使用场景是在做一个活动库的时候，需要提供多个跟活动有关的接口供前段调用，包括获取活动展示的相关信息，活动参与记录，以及活动逻辑处理。</li><li>设计的时候，活动分为模板活动和特殊活动，接口通过一个通用控制器提供，同一个接口对于不同的模板和不同活动返回数据的含义相近，但是处理各不相同，可以根据参数决定调用接口的时候具体去执行什么样的操作。</li><li>问题在于扩展的时候，可能出现额外的模板或特殊活动需要特定的接口，专门在控制器中添加此接口并针对去实现显得浪费而且不利于维护。</li><li>可以在把特殊接口的实现写在特点模板或者特殊活动类内部，然后对外的控制器通过提供call方法实现。这样避免了控制器内不断增多的接口方法，也避免了混乱，形成了公共接口在控制器内，大家一起实现；特殊接口自己实现，通过call调用。<h4 id="参考代码如下"><a href="#参考代码如下" class="headerlink" title="参考代码如下"></a>参考代码如下</h4><pre class=" language-$xslt"><code class="language-$xslt">public function __call($name,$arr) {  //获取请求参数 进行业务上的参数判断 ...  //根据参数得知此活动应该调用哪个类处理(特殊活动类or某个模板类) $actClassName   if(!$actClassName||!class_exists($actClassName)) {        //判断类是否存在      //类不存在 返回异常   }   $actClass = new $actClassName();   if(!in_array($name,get_class_methods($actClass))) {       //判断要请求的方法是可访问，是否存在      //方法不存在 返回异常   }   //调用此特定方法   $actClass->$name($params);}</code></pre><h3 id="分享心得"><a href="#分享心得" class="headerlink" title="分享心得"></a>分享心得</h3></li><li>此处控制器不需要管理非通用的接口，而是通过__call丢给实际处理逻辑类让他们自己去找实现方法；</li><li>合理利用php中的魔术方法，可以编写相对更加优雅的代码。</li></ul>]]></content>
      
      
      <categories>
          
          <category> php </category>
          
      </categories>
      
      
        <tags>
            
            <tag> php </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hexo+github建立个人blog</title>
      <link href="/2015/10/17/hexo-github-jian-li-ge-ren-blog/"/>
      <url>/2015/10/17/hexo-github-jian-li-ge-ren-blog/</url>
      
        <content type="html"><![CDATA[<p>本文将根据我的个人博客，给大家分享基于hexo+github建立个人博客的过程。<br>欢迎讨论和吐槽。</p><h3 id="完整过程"><a href="#完整过程" class="headerlink" title="完整过程"></a>完整过程</h3><h3 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h3><p><a href="https://hexo.io/zh-cn/docs/writing.html" target="_blank" rel="noopener">参考1</a><br><a href="http://www.cnblogs.com/jarson-7426/p/5430757.html" target="_blank" rel="noopener">参考2</a></p><h3 id="建好之后"><a href="#建好之后" class="headerlink" title="建好之后"></a>建好之后</h3><p>不管是建立自己的博客站还是用已有的博客社区，重点在于坚持创作，坚持学习。</p>]]></content>
      
      
      <categories>
          
          <category> hexo </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hexo </tag>
            
            <tag> blog </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
